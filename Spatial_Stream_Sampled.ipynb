{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spatial_Stream_Sampled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2ac1ce20b5e41208342e5a917726d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_558faa8cc4124de49c3a432e37c04007",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_604efc3f04374c5fb6d42b7c7168a035",
              "IPY_MODEL_0c11d17f29ab4864845384c6862f629f"
            ]
          }
        },
        "558faa8cc4124de49c3a432e37c04007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "604efc3f04374c5fb6d42b7c7168a035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3811e599c794585aded5b04075a8109",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_790b18b1f19a494bb6bc15cfb14f4e39"
          }
        },
        "0c11d17f29ab4864845384c6862f629f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_425029eadae5419b94cda4c64d988d75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:15&lt;00:00, 6.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4767defab70242f799e31ec3d7d71b41"
          }
        },
        "e3811e599c794585aded5b04075a8109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "790b18b1f19a494bb6bc15cfb14f4e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "425029eadae5419b94cda4c64d988d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4767defab70242f799e31ec3d7d71b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgqAhYHvNg2"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA580dbFbyEn",
        "outputId": "cc72a8d7-8b70-4442-c984-267b7b882466"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 12 06:11:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOC44nKYDOn8"
      },
      "source": [
        "# Run this command once and restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZffaB6C7Z7",
        "outputId": "e491cce7-7030-465d-92b2-6c0b8ac099a6"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n",
            "\u001b[K     |████████████████████████████████| 36.9MB 138kB/s \n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-8.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwpGXLdtuq8i"
      },
      "source": [
        "# Mount drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6nsoL9Kuqil",
        "outputId": "10e4d87c-da0a-4e71-e2e3-8e3d54cb7140"
      },
      "source": [
        "import os\n",
        "import io\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive\n",
        "DRIVE_MOUNT='/content/drive'\n",
        "\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "\n",
        "# create folder to write data to\n",
        "DATA_FOLDER = os.path.join(DRIVE_MOUNT, 'Shared drives', 'CIS680 Final Project', 'data')\n",
        "TRAIN_FOLDER = os.path.join(DATA_FOLDER, 'dataset_1', 'train')\n",
        "TEST_FOLDER = os.path.join(DATA_FOLDER, 'dataset_1', 'test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6FpL-ddpSI"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8J0AEPhdqg8"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "# from dataset import *\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SpatialStream(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 device='cuda',\n",
        "                 num_classes=51,\n",
        "                 dropout_probability=0.5,\n",
        "                 train_resnet=True):\n",
        "\n",
        "        # Initialize the stream layers\n",
        "        super(SpatialStream, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Spatial Backbone\n",
        "        self.spatial = models.resnet50(pretrained=True)\n",
        "        for param in self.spatial.parameters():\n",
        "            param.requires_grad = train_resnet  # False: Freezes the weights of the pre-trained model\n",
        "\n",
        "        # Add to Spatial Backbone\n",
        "        self.spatial.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Linear(1024, self.num_classes),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Softmax())\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.spatial(X)\n",
        "\n",
        "    def compute_loss(self, output, labels):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # labels = torch.tensor(labels)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        return loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q86rcNdPQNL0"
      },
      "source": [
        "# Cache data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeWp2LAFp8CA",
        "outputId": "740a2d76-6185-4eae-adda-4ee50a9ce762"
      },
      "source": [
        "data_train = []\r\n",
        "data_test = []\r\n",
        "for iter in range(b_train):\r\n",
        "  data_train.append(torch.load(TRAIN_FOLDER + '/train_b{}.pt'.format(iter)))\r\n",
        "  if iter%5==0:\r\n",
        "    print(iter)\r\n",
        "for iter in range(b_test):\r\n",
        "  data_test.append(torch.load(TEST_FOLDER + '/test_b{}.pt'.format(iter)))\r\n",
        "  if iter%5==0:\r\n",
        "    print(iter)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n",
            "50\n",
            "55\n",
            "60\n",
            "65\n",
            "70\n",
            "75\n",
            "80\n",
            "85\n",
            "90\n",
            "95\n",
            "100\n",
            "105\n",
            "110\n",
            "115\n",
            "120\n",
            "125\n",
            "130\n",
            "135\n",
            "140\n",
            "145\n",
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pEvnrSVeftj"
      },
      "source": [
        "# Train & Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkzqmwzefQq"
      },
      "source": [
        "import torchvision.transforms as tf\n",
        "trans = tf.RandomHorizontalFlip()\n",
        "b_train = 146\n",
        "n_train = 18665\n",
        "b_test = 43\n",
        "n_test = 5477\n",
        "batch_size = 128\n",
        "\n",
        "def train(epoch):\n",
        "    \n",
        "    spatial.train()\n",
        "    counter = 0\n",
        "    train_loss = 0\n",
        "    log_interval = 25\n",
        "    save_interval = 50\n",
        "\n",
        "    epoch_loss = []\n",
        "    log_int_loss = 0\n",
        "    num_iter = 0\n",
        "\n",
        "    for iter in range(b_train):\n",
        "        data = data_train[iter]#torch.load(TRAIN_FOLDER + '/train_b{}.pt'.format(iter))\n",
        "\n",
        "        videos = data[\"videos\"].clone().squeeze(1).permute(0, 3, 1, 2)\n",
        "        videos = trans(videos)\n",
        "        labels = torch.tensor(data[\"labels\"].copy())\n",
        "\n",
        "        num_iter+=videos.shape[0]\n",
        "\n",
        "        videos = videos.type(torch.FloatTensor)\n",
        "        videos = videos.to(device)\n",
        "        # labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = spatial(videos)\n",
        "        output = output.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = spatial.compute_loss(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Logging Interval\n",
        "        log_int_loss += loss.item()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if counter == 0:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss)\n",
        "            train_loss_list.append(train_loss / num_iter)\n",
        "            train_counter.append(num_iter + epoch * n_train)\n",
        "            log_int_loss = 0\n",
        "        elif counter % log_interval == log_interval - 1:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss / log_interval)\n",
        "            train_loss_list.append(train_loss / num_iter)\n",
        "            train_counter.append(num_iter + epoch * n_train)\n",
        "            log_int_loss = 0\n",
        "\n",
        "        if counter % save_interval == save_interval - 1 or counter==b_train-1:\n",
        "            print('saving model')\n",
        "            save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch) + '_iter_' + str(counter))\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_total_loss_list': train_loss_list,\n",
        "                'epoch_total_loss_list': epoch_loss_list,\n",
        "                'test_loss_list': test_loss_list,\n",
        "                'train_counter': train_counter,\n",
        "                'accuracy_list': accuracy_list,\n",
        "                'model_state_dict': spatial.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, save_path)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "    epoch_loss_list.append(avg_loss)\n",
        "    print('Epoch: ', epoch, ', avg total loss: ', avg_loss)\n",
        "\n",
        "def test():\n",
        "    spatial.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Data Loop\n",
        "    with torch.no_grad():\n",
        "        for iter in range(b_test):\n",
        "            data = data_test[iter]#torch.load(TRAIN_FOLDER + '/test_b{}.pt'.format(iter))\n",
        "            videos = data[\"videos\"].clone().squeeze(1).permute(0, 3, 1, 2)\n",
        "            labels = torch.tensor(data[\"labels\"].copy())\n",
        "\n",
        "            videos = videos.type(torch.FloatTensor)\n",
        "            videos = videos.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = spatial(videos)\n",
        "            output = output.to(device)\n",
        "\n",
        "            # calculate losses\n",
        "            loss = spatial.compute_loss(output, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # calculate number of correct predictions in batch\n",
        "            correct += sum(torch.argmax(output,1) == labels).item()\n",
        "            if iter % 100 == 0:\n",
        "                print (\"iter  \", iter)\n",
        "                print(\"accuracy so far = \", correct / ((iter + 1) * len(labels)))\n",
        "\n",
        "    # Log\n",
        "    test_loss_list.append(test_loss / n_test)\n",
        "    accuracy = correct / n_test\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('Avg Validation Loss: ', test_loss / n_test)\n",
        "    print('Accuracy: ', accuracy)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxNfXCLLYcbW"
      },
      "source": [
        "# Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiW7i49DYbwc",
        "outputId": "263299f3-a2f6-4241-c1ec-6cd5893536d5"
      },
      "source": [
        "import numpy as np\n",
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# initialize weights\n",
        "# for m in spatial.modules():\n",
        "#     if isinstance(m, torch.nn.Linear):\n",
        "#         torch.nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "#         torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 100++\n",
        ";//+;*6333-++++++++++++++\n",
        "# Logging setup: train\n",
        "train_loss_list = []\n",
        "epoch_loss_list = []\n",
        "train_counter = []\n",
        "\n",
        "# Logging setup: test\n",
        "test_loss_list = []\n",
        "accuracy_list = []\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Adjust Learning Rate\n",
        "    # if epoch == 8 or epoch == 13:\n",
        "    #     pass\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': spatial.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 , Batch:  0 , loss avg over log interval:  3.9316935539245605\n",
            "Epoch:  0 , Batch:  24 , loss avg over log interval:  3.7745861434936523\n",
            "Epoch:  0 , Batch:  49 , loss avg over log interval:  3.9320147800445557\n",
            "saving model\n",
            "Epoch:  0 , Batch:  74 , loss avg over log interval:  3.931882858276367\n",
            "Epoch:  0 , Batch:  99 , loss avg over log interval:  3.9316771697998045\n",
            "saving model\n",
            "Epoch:  0 , Batch:  124 , loss avg over log interval:  3.93158164024353\n",
            "saving model\n",
            "Epoch:  0 , avg total loss:  3.9317470348044616\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.030866728922474964\n",
            "Accuracy:  0.04619317144422129\n",
            "Epoch 0/99 Completed\n",
            "Epoch:  1 , Batch:  0 , loss avg over log interval:  3.931469440460205\n",
            "Epoch:  1 , Batch:  24 , loss avg over log interval:  3.774281129837036\n",
            "Epoch:  1 , Batch:  49 , loss avg over log interval:  3.9311986637115477\n",
            "saving model\n",
            "Epoch:  1 , Batch:  74 , loss avg over log interval:  3.9310523414611818\n",
            "Epoch:  1 , Batch:  99 , loss avg over log interval:  3.930758457183838\n",
            "saving model\n",
            "Epoch:  1 , Batch:  124 , loss avg over log interval:  3.930634870529175\n",
            "saving model\n",
            "Epoch:  1 , avg total loss:  3.9309911140023845\n",
            "iter   0\n",
            "accuracy so far =  0.1875\n",
            "Avg Validation Loss:  0.03086497441072936\n",
            "Accuracy:  0.02556143874383787\n",
            "Epoch 1/99 Completed\n",
            "Epoch:  2 , Batch:  0 , loss avg over log interval:  3.93099308013916\n",
            "Epoch:  2 , Batch:  24 , loss avg over log interval:  3.7729117107391357\n",
            "Epoch:  2 , Batch:  49 , loss avg over log interval:  3.929643335342407\n",
            "saving model\n",
            "Epoch:  2 , Batch:  74 , loss avg over log interval:  3.9289041805267333\n",
            "Epoch:  2 , Batch:  99 , loss avg over log interval:  3.9273529624938965\n",
            "saving model\n",
            "Epoch:  2 , Batch:  124 , loss avg over log interval:  3.9266126441955564\n",
            "saving model\n",
            "Epoch:  2 , avg total loss:  3.927997674027534\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03086302222529967\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 2/99 Completed\n",
            "Epoch:  3 , Batch:  0 , loss avg over log interval:  3.9199559688568115\n",
            "Epoch:  3 , Batch:  24 , loss avg over log interval:  3.7629707622528077\n",
            "Epoch:  3 , Batch:  49 , loss avg over log interval:  3.914109983444214\n",
            "saving model\n",
            "Epoch:  3 , Batch:  74 , loss avg over log interval:  3.9035561752319334\n",
            "Epoch:  3 , Batch:  99 , loss avg over log interval:  3.900063591003418\n",
            "saving model\n",
            "Epoch:  3 , Batch:  124 , loss avg over log interval:  3.90510781288147\n",
            "saving model\n",
            "Epoch:  3 , avg total loss:  3.9080190429948782\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030859011160276093\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 3/99 Completed\n",
            "Epoch:  4 , Batch:  0 , loss avg over log interval:  3.896894693374634\n",
            "Epoch:  4 , Batch:  24 , loss avg over log interval:  3.741960573196411\n",
            "Epoch:  4 , Batch:  49 , loss avg over log interval:  3.9019147968292236\n",
            "saving model\n",
            "Epoch:  4 , Batch:  74 , loss avg over log interval:  3.8968633365631105\n",
            "Epoch:  4 , Batch:  99 , loss avg over log interval:  3.896348571777344\n",
            "saving model\n",
            "Epoch:  4 , Batch:  124 , loss avg over log interval:  3.8967878246307373\n",
            "saving model\n",
            "Epoch:  4 , avg total loss:  3.8983915799284636\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030853728166740046\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 4/99 Completed\n",
            "Epoch:  5 , Batch:  0 , loss avg over log interval:  3.903315544128418\n",
            "Epoch:  5 , Batch:  24 , loss avg over log interval:  3.7440699672698976\n",
            "Epoch:  5 , Batch:  49 , loss avg over log interval:  3.9021364974975588\n",
            "saving model\n",
            "Epoch:  5 , Batch:  74 , loss avg over log interval:  3.898153057098389\n",
            "Epoch:  5 , Batch:  99 , loss avg over log interval:  3.8920492267608644\n",
            "saving model\n",
            "Epoch:  5 , Batch:  124 , loss avg over log interval:  3.8976798248291016\n",
            "saving model\n",
            "Epoch:  5 , avg total loss:  3.8981620269278956\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030848127659032745\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 5/99 Completed\n",
            "Epoch:  6 , Batch:  0 , loss avg over log interval:  3.8849563598632812\n",
            "Epoch:  6 , Batch:  24 , loss avg over log interval:  3.741512041091919\n",
            "Epoch:  6 , Batch:  49 , loss avg over log interval:  3.898252458572388\n",
            "saving model\n",
            "Epoch:  6 , Batch:  74 , loss avg over log interval:  3.893071622848511\n",
            "Epoch:  6 , Batch:  99 , loss avg over log interval:  3.8889456176757813\n",
            "saving model\n",
            "Epoch:  6 , Batch:  124 , loss avg over log interval:  3.8970647430419922\n",
            "saving model\n",
            "Epoch:  6 , avg total loss:  3.895768461162097\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03083933768795641\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 6/99 Completed\n",
            "Epoch:  7 , Batch:  0 , loss avg over log interval:  3.8891208171844482\n",
            "Epoch:  7 , Batch:  24 , loss avg over log interval:  3.7407072448730467\n",
            "Epoch:  7 , Batch:  49 , loss avg over log interval:  3.899588232040405\n",
            "saving model\n",
            "Epoch:  7 , Batch:  74 , loss avg over log interval:  3.8929997444152833\n",
            "Epoch:  7 , Batch:  99 , loss avg over log interval:  3.8958272457122805\n",
            "saving model\n",
            "Epoch:  7 , Batch:  124 , loss avg over log interval:  3.895734739303589\n",
            "saving model\n",
            "Epoch:  7 , avg total loss:  3.8966735846375764\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030828959405998994\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 7/99 Completed\n",
            "Epoch:  8 , Batch:  0 , loss avg over log interval:  3.8780739307403564\n",
            "Epoch:  8 , Batch:  24 , loss avg over log interval:  3.7385708713531494\n",
            "Epoch:  8 , Batch:  49 , loss avg over log interval:  3.893448715209961\n",
            "saving model\n",
            "Epoch:  8 , Batch:  74 , loss avg over log interval:  3.8921754264831545\n",
            "Epoch:  8 , Batch:  99 , loss avg over log interval:  3.8894003200531007\n",
            "saving model\n",
            "Epoch:  8 , Batch:  124 , loss avg over log interval:  3.898850688934326\n",
            "saving model\n",
            "Epoch:  8 , avg total loss:  3.89410526785132\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03081334196609238\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 8/99 Completed\n",
            "Epoch:  9 , Batch:  0 , loss avg over log interval:  3.8924081325531006\n",
            "Epoch:  9 , Batch:  24 , loss avg over log interval:  3.74031005859375\n",
            "Epoch:  9 , Batch:  49 , loss avg over log interval:  3.8972435760498048\n",
            "saving model\n",
            "Epoch:  9 , Batch:  74 , loss avg over log interval:  3.8933589363098147\n",
            "Epoch:  9 , Batch:  99 , loss avg over log interval:  3.895781984329224\n",
            "saving model\n",
            "Epoch:  9 , Batch:  124 , loss avg over log interval:  3.8926061534881593\n",
            "saving model\n",
            "Epoch:  9 , avg total loss:  3.894934270479908\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030793691652195938\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 9/99 Completed\n",
            "Epoch:  10 , Batch:  0 , loss avg over log interval:  3.890251874923706\n",
            "Epoch:  10 , Batch:  24 , loss avg over log interval:  3.7361621284484863\n",
            "Epoch:  10 , Batch:  49 , loss avg over log interval:  3.8900469970703124\n",
            "saving model\n",
            "Epoch:  10 , Batch:  74 , loss avg over log interval:  3.8878743648529053\n",
            "Epoch:  10 , Batch:  99 , loss avg over log interval:  3.890440273284912\n",
            "saving model\n",
            "Epoch:  10 , Batch:  124 , loss avg over log interval:  3.894896774291992\n",
            "saving model\n",
            "Epoch:  10 , avg total loss:  3.8919667756720764\n",
            "iter   0\n",
            "accuracy so far =  0.0703125\n",
            "Avg Validation Loss:  0.03076906754453839\n",
            "Accuracy:  0.03231696184042359\n",
            "Epoch 10/99 Completed\n",
            "Epoch:  11 , Batch:  0 , loss avg over log interval:  3.8985774517059326\n",
            "Epoch:  11 , Batch:  24 , loss avg over log interval:  3.733230094909668\n",
            "Epoch:  11 , Batch:  49 , loss avg over log interval:  3.889878149032593\n",
            "saving model\n",
            "Epoch:  11 , Batch:  74 , loss avg over log interval:  3.8875068187713624\n",
            "Epoch:  11 , Batch:  99 , loss avg over log interval:  3.8795909214019777\n",
            "saving model\n",
            "Epoch:  11 , Batch:  124 , loss avg over log interval:  3.88046856880188\n",
            "saving model\n",
            "Epoch:  11 , avg total loss:  3.885858031168376\n",
            "iter   0\n",
            "accuracy so far =  0.4375\n",
            "Avg Validation Loss:  0.03074724499666062\n",
            "Accuracy:  0.05568742012050393\n",
            "Epoch 11/99 Completed\n",
            "Epoch:  12 , Batch:  0 , loss avg over log interval:  3.8762669563293457\n",
            "Epoch:  12 , Batch:  24 , loss avg over log interval:  3.7291894245147703\n",
            "Epoch:  12 , Batch:  49 , loss avg over log interval:  3.8798507499694823\n",
            "saving model\n",
            "Epoch:  12 , Batch:  74 , loss avg over log interval:  3.878203020095825\n",
            "Epoch:  12 , Batch:  99 , loss avg over log interval:  3.881896514892578\n",
            "saving model\n",
            "Epoch:  12 , Batch:  124 , loss avg over log interval:  3.8758604907989502\n",
            "saving model\n",
            "Epoch:  12 , avg total loss:  3.8807347392382687\n",
            "iter   0\n",
            "accuracy so far =  0.7890625\n",
            "Avg Validation Loss:  0.030723866046030026\n",
            "Accuracy:  0.08234434909622056\n",
            "Epoch 12/99 Completed\n",
            "Epoch:  13 , Batch:  0 , loss avg over log interval:  3.8759195804595947\n",
            "Epoch:  13 , Batch:  24 , loss avg over log interval:  3.719972915649414\n",
            "Epoch:  13 , Batch:  49 , loss avg over log interval:  3.88291690826416\n",
            "saving model\n",
            "Epoch:  13 , Batch:  74 , loss avg over log interval:  3.879894847869873\n",
            "Epoch:  13 , Batch:  99 , loss avg over log interval:  3.875617055892944\n",
            "saving model\n",
            "Epoch:  13 , Batch:  124 , loss avg over log interval:  3.8802913284301757\n",
            "saving model\n",
            "Epoch:  13 , avg total loss:  3.878595740827796\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030698907142445536\n",
            "Accuracy:  0.08909987219280628\n",
            "Epoch 13/99 Completed\n",
            "Epoch:  14 , Batch:  0 , loss avg over log interval:  3.883164882659912\n",
            "Epoch:  14 , Batch:  24 , loss avg over log interval:  3.717197217941284\n",
            "Epoch:  14 , Batch:  49 , loss avg over log interval:  3.881415157318115\n",
            "saving model\n",
            "Epoch:  14 , Batch:  74 , loss avg over log interval:  3.8742488956451417\n",
            "Epoch:  14 , Batch:  99 , loss avg over log interval:  3.871498022079468\n",
            "saving model\n",
            "Epoch:  14 , Batch:  124 , loss avg over log interval:  3.8790388202667234\n",
            "saving model\n",
            "Epoch:  14 , avg total loss:  3.87563886217875\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030670754770651905\n",
            "Accuracy:  0.09202117947781632\n",
            "Epoch 14/99 Completed\n",
            "Epoch:  15 , Batch:  0 , loss avg over log interval:  3.8669185638427734\n",
            "Epoch:  15 , Batch:  24 , loss avg over log interval:  3.720786714553833\n",
            "Epoch:  15 , Batch:  49 , loss avg over log interval:  3.8756790733337403\n",
            "saving model\n",
            "Epoch:  15 , Batch:  74 , loss avg over log interval:  3.8681865978240966\n",
            "Epoch:  15 , Batch:  99 , loss avg over log interval:  3.8665345096588135\n",
            "saving model\n",
            "Epoch:  15 , Batch:  124 , loss avg over log interval:  3.870828514099121\n",
            "saving model\n",
            "Epoch:  15 , avg total loss:  3.872109238415548\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.0306385630387687\n",
            "Accuracy:  0.09256892459375571\n",
            "Epoch 15/99 Completed\n",
            "Epoch:  16 , Batch:  0 , loss avg over log interval:  3.8661179542541504\n",
            "Epoch:  16 , Batch:  24 , loss avg over log interval:  3.7157836723327637\n",
            "Epoch:  16 , Batch:  49 , loss avg over log interval:  3.8695575904846193\n",
            "saving model\n",
            "Epoch:  16 , Batch:  74 , loss avg over log interval:  3.867466678619385\n",
            "Epoch:  16 , Batch:  99 , loss avg over log interval:  3.8685753250122072\n",
            "saving model\n",
            "Epoch:  16 , Batch:  124 , loss avg over log interval:  3.8700973701477053\n",
            "saving model\n",
            "Epoch:  16 , avg total loss:  3.8697162050090426\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.03062562993000693\n",
            "Accuracy:  0.09329925141500822\n",
            "Epoch 16/99 Completed\n",
            "Epoch:  17 , Batch:  0 , loss avg over log interval:  3.892667055130005\n",
            "Epoch:  17 , Batch:  24 , loss avg over log interval:  3.706538209915161\n",
            "Epoch:  17 , Batch:  49 , loss avg over log interval:  3.867976636886597\n",
            "saving model\n",
            "Epoch:  17 , Batch:  74 , loss avg over log interval:  3.8685114669799803\n",
            "Epoch:  17 , Batch:  99 , loss avg over log interval:  3.8634876155853273\n",
            "saving model\n",
            "Epoch:  17 , Batch:  124 , loss avg over log interval:  3.8736328887939453\n",
            "saving model\n",
            "Epoch:  17 , avg total loss:  3.8674844585052908\n",
            "iter   0\n",
            "accuracy so far =  0.90625\n",
            "Avg Validation Loss:  0.030610429559372977\n",
            "Accuracy:  0.09329925141500822\n",
            "Epoch 17/99 Completed\n",
            "Epoch:  18 , Batch:  0 , loss avg over log interval:  3.8545613288879395\n",
            "Epoch:  18 , Batch:  24 , loss avg over log interval:  3.7103826713562014\n",
            "Epoch:  18 , Batch:  49 , loss avg over log interval:  3.8648317432403565\n",
            "saving model\n",
            "Epoch:  18 , Batch:  74 , loss avg over log interval:  3.8683555507659912\n",
            "Epoch:  18 , Batch:  99 , loss avg over log interval:  3.865198001861572\n",
            "saving model\n",
            "Epoch:  18 , Batch:  124 , loss avg over log interval:  3.862558603286743\n",
            "saving model\n",
            "Epoch:  18 , avg total loss:  3.8662018106408316\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030598273781370196\n",
            "Accuracy:  0.0931166697096951\n",
            "Epoch 18/99 Completed\n",
            "Epoch:  19 , Batch:  0 , loss avg over log interval:  3.8602306842803955\n",
            "Epoch:  19 , Batch:  24 , loss avg over log interval:  3.710045118331909\n",
            "Epoch:  19 , Batch:  49 , loss avg over log interval:  3.8653432083129884\n",
            "saving model\n",
            "Epoch:  19 , Batch:  74 , loss avg over log interval:  3.86399224281311\n",
            "Epoch:  19 , Batch:  99 , loss avg over log interval:  3.8634203243255616\n",
            "saving model\n",
            "Epoch:  19 , Batch:  124 , loss avg over log interval:  3.863007593154907\n",
            "saving model\n",
            "Epoch:  19 , avg total loss:  3.8652269448319525\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030586403609410416\n",
            "Accuracy:  0.09348183312032135\n",
            "Epoch 19/99 Completed\n",
            "Epoch:  20 , Batch:  0 , loss avg over log interval:  3.8622305393218994\n",
            "Epoch:  20 , Batch:  24 , loss avg over log interval:  3.704039602279663\n",
            "Epoch:  20 , Batch:  49 , loss avg over log interval:  3.860063199996948\n",
            "saving model\n",
            "Epoch:  20 , Batch:  74 , loss avg over log interval:  3.8567872524261473\n",
            "Epoch:  20 , Batch:  99 , loss avg over log interval:  3.8603027725219725\n",
            "saving model\n",
            "Epoch:  20 , Batch:  124 , loss avg over log interval:  3.86739821434021\n",
            "saving model\n",
            "Epoch:  20 , avg total loss:  3.860950035591648\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030567484265895617\n",
            "Accuracy:  0.09475990505751324\n",
            "Epoch 20/99 Completed\n",
            "Epoch:  21 , Batch:  0 , loss avg over log interval:  3.865842580795288\n",
            "Epoch:  21 , Batch:  24 , loss avg over log interval:  3.7039386463165282\n",
            "Epoch:  21 , Batch:  49 , loss avg over log interval:  3.8558044910430906\n",
            "saving model\n",
            "Epoch:  21 , Batch:  74 , loss avg over log interval:  3.8647477626800537\n",
            "Epoch:  21 , Batch:  99 , loss avg over log interval:  3.8527056694030763\n",
            "saving model\n",
            "Epoch:  21 , Batch:  124 , loss avg over log interval:  3.865658359527588\n",
            "saving model\n",
            "Epoch:  21 , avg total loss:  3.859567782650255\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030551284295876616\n",
            "Accuracy:  0.1024283366806646\n",
            "Epoch 21/99 Completed\n",
            "Epoch:  22 , Batch:  0 , loss avg over log interval:  3.874671697616577\n",
            "Epoch:  22 , Batch:  24 , loss avg over log interval:  3.7018282222747803\n",
            "Epoch:  22 , Batch:  49 , loss avg over log interval:  3.863027458190918\n",
            "saving model\n",
            "Epoch:  22 , Batch:  74 , loss avg over log interval:  3.86163423538208\n",
            "Epoch:  22 , Batch:  99 , loss avg over log interval:  3.8477875900268557\n",
            "saving model\n",
            "Epoch:  22 , Batch:  124 , loss avg over log interval:  3.8589835929870606\n",
            "saving model\n",
            "Epoch:  22 , avg total loss:  3.859403375076921\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030532184125124723\n",
            "Accuracy:  0.11484389264195728\n",
            "Epoch 22/99 Completed\n",
            "Epoch:  23 , Batch:  0 , loss avg over log interval:  3.860783338546753\n",
            "Epoch:  23 , Batch:  24 , loss avg over log interval:  3.6981325340270996\n",
            "Epoch:  23 , Batch:  49 , loss avg over log interval:  3.850195779800415\n",
            "saving model\n",
            "Epoch:  23 , Batch:  74 , loss avg over log interval:  3.852111692428589\n",
            "Epoch:  23 , Batch:  99 , loss avg over log interval:  3.8530770683288575\n",
            "saving model\n",
            "Epoch:  23 , Batch:  124 , loss avg over log interval:  3.855974349975586\n",
            "saving model\n",
            "Epoch:  23 , avg total loss:  3.853689036957205\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.030493012522832742\n",
            "Accuracy:  0.13182399123607816\n",
            "Epoch 23/99 Completed\n",
            "Epoch:  24 , Batch:  0 , loss avg over log interval:  3.8556551933288574\n",
            "Epoch:  24 , Batch:  24 , loss avg over log interval:  3.7044108963012694\n",
            "Epoch:  24 , Batch:  49 , loss avg over log interval:  3.854782152175903\n",
            "saving model\n",
            "Epoch:  24 , Batch:  74 , loss avg over log interval:  3.8613535881042482\n",
            "Epoch:  24 , Batch:  99 , loss avg over log interval:  3.8449140071868895\n",
            "saving model\n",
            "Epoch:  24 , Batch:  124 , loss avg over log interval:  3.846728467941284\n",
            "saving model\n",
            "Epoch:  24 , avg total loss:  3.8535745846082086\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.03046775073144957\n",
            "Accuracy:  0.140222749680482\n",
            "Epoch 24/99 Completed\n",
            "Epoch:  25 , Batch:  0 , loss avg over log interval:  3.8336968421936035\n",
            "Epoch:  25 , Batch:  24 , loss avg over log interval:  3.696816253662109\n",
            "Epoch:  25 , Batch:  49 , loss avg over log interval:  3.8499246311187743\n",
            "saving model\n",
            "Epoch:  25 , Batch:  74 , loss avg over log interval:  3.84529559135437\n",
            "Epoch:  25 , Batch:  99 , loss avg over log interval:  3.8507780265808105\n",
            "saving model\n",
            "Epoch:  25 , Batch:  124 , loss avg over log interval:  3.8415605354309084\n",
            "saving model\n",
            "Epoch:  25 , avg total loss:  3.8481979402777267\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030440525001301608\n",
            "Accuracy:  0.1440569654920577\n",
            "Epoch 25/99 Completed\n",
            "Epoch:  26 , Batch:  0 , loss avg over log interval:  3.898146152496338\n",
            "Epoch:  26 , Batch:  24 , loss avg over log interval:  3.688056230545044\n",
            "Epoch:  26 , Batch:  49 , loss avg over log interval:  3.846546936035156\n",
            "saving model\n",
            "Epoch:  26 , Batch:  74 , loss avg over log interval:  3.8463042831420897\n",
            "Epoch:  26 , Batch:  99 , loss avg over log interval:  3.836005754470825\n",
            "saving model\n",
            "Epoch:  26 , Batch:  124 , loss avg over log interval:  3.8436234474182127\n",
            "saving model\n",
            "Epoch:  26 , avg total loss:  3.843546317048269\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030410589996819865\n",
            "Accuracy:  0.1480737630089465\n",
            "Epoch 26/99 Completed\n",
            "Epoch:  27 , Batch:  0 , loss avg over log interval:  3.8540892601013184\n",
            "Epoch:  27 , Batch:  24 , loss avg over log interval:  3.6863654899597167\n",
            "Epoch:  27 , Batch:  49 , loss avg over log interval:  3.840614604949951\n",
            "saving model\n",
            "Epoch:  27 , Batch:  74 , loss avg over log interval:  3.8451798152923584\n",
            "Epoch:  27 , Batch:  99 , loss avg over log interval:  3.839995098114014\n",
            "saving model\n",
            "Epoch:  27 , Batch:  124 , loss avg over log interval:  3.8435109138488768\n",
            "saving model\n",
            "Epoch:  27 , avg total loss:  3.842094120913989\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030402430178628516\n",
            "Accuracy:  0.14770859959832025\n",
            "Epoch 27/99 Completed\n",
            "Epoch:  28 , Batch:  0 , loss avg over log interval:  3.8384974002838135\n",
            "Epoch:  28 , Batch:  24 , loss avg over log interval:  3.679737062454224\n",
            "Epoch:  28 , Batch:  49 , loss avg over log interval:  3.8413397026062013\n",
            "saving model\n",
            "Epoch:  28 , Batch:  74 , loss avg over log interval:  3.8441061115264894\n",
            "Epoch:  28 , Batch:  99 , loss avg over log interval:  3.836131467819214\n",
            "saving model\n",
            "Epoch:  28 , Batch:  124 , loss avg over log interval:  3.8464269638061523\n",
            "saving model\n",
            "Epoch:  28 , avg total loss:  3.841406469475733\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.03039225239986178\n",
            "Accuracy:  0.1486215081248859\n",
            "Epoch 28/99 Completed\n",
            "Epoch:  29 , Batch:  0 , loss avg over log interval:  3.8453402519226074\n",
            "Epoch:  29 , Batch:  24 , loss avg over log interval:  3.6848777866363527\n",
            "Epoch:  29 , Batch:  49 , loss avg over log interval:  3.8353560543060303\n",
            "saving model\n",
            "Epoch:  29 , Batch:  74 , loss avg over log interval:  3.843021898269653\n",
            "Epoch:  29 , Batch:  99 , loss avg over log interval:  3.8372482299804687\n",
            "saving model\n",
            "Epoch:  29 , Batch:  124 , loss avg over log interval:  3.838442678451538\n",
            "saving model\n",
            "Epoch:  29 , avg total loss:  3.838867830903563\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.030362138309377767\n",
            "Accuracy:  0.1513602337045828\n",
            "Epoch 29/99 Completed\n",
            "Epoch:  30 , Batch:  0 , loss avg over log interval:  3.8659582138061523\n",
            "Epoch:  30 , Batch:  24 , loss avg over log interval:  3.680259370803833\n",
            "Epoch:  30 , Batch:  49 , loss avg over log interval:  3.8353388690948487\n",
            "saving model\n",
            "Epoch:  30 , Batch:  74 , loss avg over log interval:  3.838048553466797\n",
            "Epoch:  30 , Batch:  99 , loss avg over log interval:  3.8306284523010254\n",
            "saving model\n",
            "Epoch:  30 , Batch:  124 , loss avg over log interval:  3.8377813053131105\n",
            "saving model\n",
            "Epoch:  30 , avg total loss:  3.836048622653909\n",
            "iter   0\n",
            "accuracy so far =  0.875\n",
            "Avg Validation Loss:  0.03035520532171679\n",
            "Accuracy:  0.15172539711520905\n",
            "Epoch 30/99 Completed\n",
            "Epoch:  31 , Batch:  0 , loss avg over log interval:  3.828359603881836\n",
            "Epoch:  31 , Batch:  24 , loss avg over log interval:  3.6876440620422364\n",
            "Epoch:  31 , Batch:  49 , loss avg over log interval:  3.8380620098114013\n",
            "saving model\n",
            "Epoch:  31 , Batch:  74 , loss avg over log interval:  3.8357451820373534\n",
            "Epoch:  31 , Batch:  99 , loss avg over log interval:  3.831401424407959\n",
            "saving model\n",
            "Epoch:  31 , Batch:  124 , loss avg over log interval:  3.8391668128967287\n",
            "saving model\n",
            "Epoch:  31 , avg total loss:  3.8383664888878393\n",
            "iter   0\n",
            "accuracy so far =  0.8671875\n",
            "Avg Validation Loss:  0.030345364080111823\n",
            "Accuracy:  0.15647252145335036\n",
            "Epoch 31/99 Completed\n",
            "Epoch:  32 , Batch:  0 , loss avg over log interval:  3.835176944732666\n",
            "Epoch:  32 , Batch:  24 , loss avg over log interval:  3.6828221893310547\n",
            "Epoch:  32 , Batch:  49 , loss avg over log interval:  3.842431049346924\n",
            "saving model\n",
            "Epoch:  32 , Batch:  74 , loss avg over log interval:  3.8312861156463622\n",
            "Epoch:  32 , Batch:  99 , loss avg over log interval:  3.8290432834625245\n",
            "saving model\n",
            "Epoch:  32 , Batch:  124 , loss avg over log interval:  3.841497735977173\n",
            "saving model\n",
            "Epoch:  32 , avg total loss:  3.8370508527102536\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030340149125326763\n",
            "Accuracy:  0.16176739090743109\n",
            "Epoch 32/99 Completed\n",
            "Epoch:  33 , Batch:  0 , loss avg over log interval:  3.8404757976531982\n",
            "Epoch:  33 , Batch:  24 , loss avg over log interval:  3.679731912612915\n",
            "Epoch:  33 , Batch:  49 , loss avg over log interval:  3.838310956954956\n",
            "saving model\n",
            "Epoch:  33 , Batch:  74 , loss avg over log interval:  3.834595966339111\n",
            "Epoch:  33 , Batch:  99 , loss avg over log interval:  3.829091033935547\n",
            "saving model\n",
            "Epoch:  33 , Batch:  124 , loss avg over log interval:  3.8393278026580813\n",
            "saving model\n",
            "Epoch:  33 , avg total loss:  3.8346811532974243\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.03033022848341355\n",
            "Accuracy:  0.165966770129633\n",
            "Epoch 33/99 Completed\n",
            "Epoch:  34 , Batch:  0 , loss avg over log interval:  3.8575785160064697\n",
            "Epoch:  34 , Batch:  24 , loss avg over log interval:  3.673376340866089\n",
            "Epoch:  34 , Batch:  49 , loss avg over log interval:  3.8274487686157226\n",
            "saving model\n",
            "Epoch:  34 , Batch:  74 , loss avg over log interval:  3.825390157699585\n",
            "Epoch:  34 , Batch:  99 , loss avg over log interval:  3.823269805908203\n",
            "saving model\n",
            "Epoch:  34 , Batch:  124 , loss avg over log interval:  3.8385088443756104\n",
            "saving model\n",
            "Epoch:  34 , avg total loss:  3.8302568850451952\n",
            "iter   0\n",
            "accuracy so far =  0.875\n",
            "Avg Validation Loss:  0.03032267178543645\n",
            "Accuracy:  0.1699835676465218\n",
            "Epoch 34/99 Completed\n",
            "Epoch:  35 , Batch:  0 , loss avg over log interval:  3.815263271331787\n",
            "Epoch:  35 , Batch:  24 , loss avg over log interval:  3.671091842651367\n",
            "Epoch:  35 , Batch:  49 , loss avg over log interval:  3.8281429958343507\n",
            "saving model\n",
            "Epoch:  35 , Batch:  74 , loss avg over log interval:  3.8335103797912597\n",
            "Epoch:  35 , Batch:  99 , loss avg over log interval:  3.8244942569732667\n",
            "saving model\n",
            "Epoch:  35 , Batch:  124 , loss avg over log interval:  3.829735879898071\n",
            "saving model\n",
            "Epoch:  35 , avg total loss:  3.828523790999635\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.030307631260159895\n",
            "Accuracy:  0.16943582253058243\n",
            "Epoch 35/99 Completed\n",
            "Epoch:  36 , Batch:  0 , loss avg over log interval:  3.8056201934814453\n",
            "Epoch:  36 , Batch:  24 , loss avg over log interval:  3.6678091621398927\n",
            "Epoch:  36 , Batch:  49 , loss avg over log interval:  3.8212135791778565\n",
            "saving model\n",
            "Epoch:  36 , Batch:  74 , loss avg over log interval:  3.834668617248535\n",
            "Epoch:  36 , Batch:  99 , loss avg over log interval:  3.8239270782470705\n",
            "saving model\n",
            "Epoch:  36 , Batch:  124 , loss avg over log interval:  3.8303590488433836\n",
            "saving model\n",
            "Epoch:  36 , avg total loss:  3.825991544004989\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.030294523592606412\n",
            "Accuracy:  0.16870549570932994\n",
            "Epoch 36/99 Completed\n",
            "Epoch:  37 , Batch:  0 , loss avg over log interval:  3.8051116466522217\n",
            "Epoch:  37 , Batch:  24 , loss avg over log interval:  3.6696235084533693\n",
            "Epoch:  37 , Batch:  49 , loss avg over log interval:  3.8300929164886472\n",
            "saving model\n",
            "Epoch:  37 , Batch:  74 , loss avg over log interval:  3.8266465568542483\n",
            "Epoch:  37 , Batch:  99 , loss avg over log interval:  3.8179730987548828\n",
            "saving model\n",
            "Epoch:  37 , Batch:  124 , loss avg over log interval:  3.825390033721924\n",
            "saving model\n",
            "Epoch:  37 , avg total loss:  3.826297291337627\n",
            "iter   0\n",
            "accuracy so far =  0.828125\n",
            "Avg Validation Loss:  0.030295337924605547\n",
            "Accuracy:  0.17290487493153187\n",
            "Epoch 37/99 Completed\n",
            "Epoch:  38 , Batch:  0 , loss avg over log interval:  3.850527286529541\n",
            "Epoch:  38 , Batch:  24 , loss avg over log interval:  3.665460214614868\n",
            "Epoch:  38 , Batch:  49 , loss avg over log interval:  3.816428289413452\n",
            "saving model\n",
            "Epoch:  38 , Batch:  74 , loss avg over log interval:  3.8290438556671145\n",
            "Epoch:  38 , Batch:  99 , loss avg over log interval:  3.823926315307617\n",
            "saving model\n",
            "Epoch:  38 , Batch:  124 , loss avg over log interval:  3.8198999118804933\n",
            "saving model\n",
            "Epoch:  38 , avg total loss:  3.823033094406128\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030271553179197816\n",
            "Accuracy:  0.17290487493153187\n",
            "Epoch 38/99 Completed\n",
            "Epoch:  39 , Batch:  0 , loss avg over log interval:  3.812802791595459\n",
            "Epoch:  39 , Batch:  24 , loss avg over log interval:  3.6622192001342775\n",
            "Epoch:  39 , Batch:  49 , loss avg over log interval:  3.8155573272705077\n",
            "saving model\n",
            "Epoch:  39 , Batch:  74 , loss avg over log interval:  3.813474235534668\n",
            "Epoch:  39 , Batch:  99 , loss avg over log interval:  3.8214159488677977\n",
            "saving model\n",
            "Epoch:  39 , Batch:  124 , loss avg over log interval:  3.8230933856964113\n",
            "saving model\n",
            "Epoch:  39 , avg total loss:  3.8191042795573193\n",
            "iter   0\n",
            "accuracy so far =  0.8359375\n",
            "Avg Validation Loss:  0.03026211329222117\n",
            "Accuracy:  0.17400036516341064\n",
            "Epoch 39/99 Completed\n",
            "Epoch:  40 , Batch:  0 , loss avg over log interval:  3.7923290729522705\n",
            "Epoch:  40 , Batch:  24 , loss avg over log interval:  3.6617180919647216\n",
            "Epoch:  40 , Batch:  49 , loss avg over log interval:  3.8214082431793215\n",
            "saving model\n",
            "Epoch:  40 , Batch:  74 , loss avg over log interval:  3.811834020614624\n",
            "Epoch:  40 , Batch:  99 , loss avg over log interval:  3.81620436668396\n",
            "saving model\n",
            "Epoch:  40 , Batch:  124 , loss avg over log interval:  3.8152706623077393\n",
            "saving model\n",
            "Epoch:  40 , avg total loss:  3.8161666017689115\n",
            "iter   0\n",
            "accuracy so far =  0.8203125\n",
            "Avg Validation Loss:  0.030256570549979357\n",
            "Accuracy:  0.18860690158846083\n",
            "Epoch 40/99 Completed\n",
            "Epoch:  41 , Batch:  0 , loss avg over log interval:  3.818654775619507\n",
            "Epoch:  41 , Batch:  24 , loss avg over log interval:  3.665177345275879\n",
            "Epoch:  41 , Batch:  49 , loss avg over log interval:  3.813883876800537\n",
            "saving model\n",
            "Epoch:  41 , Batch:  74 , loss avg over log interval:  3.813223705291748\n",
            "Epoch:  41 , Batch:  99 , loss avg over log interval:  3.7996556854248045\n",
            "saving model\n",
            "Epoch:  41 , Batch:  124 , loss avg over log interval:  3.8166878414154053\n",
            "saving model\n",
            "Epoch:  41 , avg total loss:  3.811220066188133\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.03023197129844901\n",
            "Accuracy:  0.1957275880956728\n",
            "Epoch 41/99 Completed\n",
            "Epoch:  42 , Batch:  0 , loss avg over log interval:  3.8308236598968506\n",
            "Epoch:  42 , Batch:  24 , loss avg over log interval:  3.6584120750427247\n",
            "Epoch:  42 , Batch:  49 , loss avg over log interval:  3.8166721630096436\n",
            "saving model\n",
            "Epoch:  42 , Batch:  74 , loss avg over log interval:  3.801827688217163\n",
            "Epoch:  42 , Batch:  99 , loss avg over log interval:  3.8030046081542968\n",
            "saving model\n",
            "Epoch:  42 , Batch:  124 , loss avg over log interval:  3.807929391860962\n",
            "saving model\n",
            "Epoch:  42 , avg total loss:  3.8080456779427725\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.030184850045009665\n",
            "Accuracy:  0.2041263465400767\n",
            "Epoch 42/99 Completed\n",
            "Epoch:  43 , Batch:  0 , loss avg over log interval:  3.749556303024292\n",
            "Epoch:  43 , Batch:  24 , loss avg over log interval:  3.6513257312774656\n",
            "Epoch:  43 , Batch:  49 , loss avg over log interval:  3.8016048526763915\n",
            "saving model\n",
            "Epoch:  43 , Batch:  74 , loss avg over log interval:  3.8083852195739745\n",
            "Epoch:  43 , Batch:  99 , loss avg over log interval:  3.7995298671722413\n",
            "saving model\n",
            "Epoch:  43 , Batch:  124 , loss avg over log interval:  3.800718584060669\n",
            "saving model\n",
            "Epoch:  43 , avg total loss:  3.80316746724795\n",
            "iter   0\n",
            "accuracy so far =  0.765625\n",
            "Avg Validation Loss:  0.030147166806719524\n",
            "Accuracy:  0.21617673909074311\n",
            "Epoch 43/99 Completed\n",
            "Epoch:  44 , Batch:  0 , loss avg over log interval:  3.8056628704071045\n",
            "Epoch:  44 , Batch:  24 , loss avg over log interval:  3.6440753078460695\n",
            "Epoch:  44 , Batch:  49 , loss avg over log interval:  3.800383138656616\n",
            "saving model\n",
            "Epoch:  44 , Batch:  74 , loss avg over log interval:  3.7951207542419434\n",
            "Epoch:  44 , Batch:  99 , loss avg over log interval:  3.8017513751983643\n",
            "saving model\n",
            "Epoch:  44 , Batch:  124 , loss avg over log interval:  3.7918595981597902\n",
            "saving model\n",
            "Epoch:  44 , avg total loss:  3.7968586683273315\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.03011497590192287\n",
            "Accuracy:  0.21617673909074311\n",
            "Epoch 44/99 Completed\n",
            "Epoch:  45 , Batch:  0 , loss avg over log interval:  3.783402919769287\n",
            "Epoch:  45 , Batch:  24 , loss avg over log interval:  3.6390627098083494\n",
            "Epoch:  45 , Batch:  49 , loss avg over log interval:  3.7904148960113524\n",
            "saving model\n",
            "Epoch:  45 , Batch:  74 , loss avg over log interval:  3.8008467102050782\n",
            "Epoch:  45 , Batch:  99 , loss avg over log interval:  3.7928754806518556\n",
            "saving model\n",
            "Epoch:  45 , Batch:  124 , loss avg over log interval:  3.7942230987548826\n",
            "saving model\n",
            "Epoch:  45 , avg total loss:  3.794451277549953\n",
            "iter   0\n",
            "accuracy so far =  0.765625\n",
            "Avg Validation Loss:  0.030075859235589773\n",
            "Accuracy:  0.21982837319700566\n",
            "Epoch 45/99 Completed\n",
            "Epoch:  46 , Batch:  0 , loss avg over log interval:  3.725555658340454\n",
            "Epoch:  46 , Batch:  24 , loss avg over log interval:  3.6396086692810057\n",
            "Epoch:  46 , Batch:  49 , loss avg over log interval:  3.788105297088623\n",
            "saving model\n",
            "Epoch:  46 , Batch:  74 , loss avg over log interval:  3.799027280807495\n",
            "Epoch:  46 , Batch:  99 , loss avg over log interval:  3.7848322105407717\n",
            "saving model\n",
            "Epoch:  46 , Batch:  124 , loss avg over log interval:  3.796048812866211\n",
            "saving model\n",
            "Epoch:  46 , avg total loss:  3.7923268210398007\n",
            "iter   0\n",
            "accuracy so far =  0.8125\n",
            "Avg Validation Loss:  0.03003584948991236\n",
            "Accuracy:  0.23443490962205588\n",
            "Epoch 46/99 Completed\n",
            "Epoch:  47 , Batch:  0 , loss avg over log interval:  3.813992500305176\n",
            "Epoch:  47 , Batch:  24 , loss avg over log interval:  3.6448364543914793\n",
            "Epoch:  47 , Batch:  49 , loss avg over log interval:  3.791837701797485\n",
            "saving model\n",
            "Epoch:  47 , Batch:  74 , loss avg over log interval:  3.79362193107605\n",
            "Epoch:  47 , Batch:  99 , loss avg over log interval:  3.7910016632080077\n",
            "saving model\n",
            "Epoch:  47 , Batch:  124 , loss avg over log interval:  3.780507402420044\n",
            "saving model\n",
            "Epoch:  47 , avg total loss:  3.7907085304390895\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.03001623234653943\n",
            "Accuracy:  0.2426510863611466\n",
            "Epoch 47/99 Completed\n",
            "Epoch:  48 , Batch:  0 , loss avg over log interval:  3.7884979248046875\n",
            "Epoch:  48 , Batch:  24 , loss avg over log interval:  3.6252852630615235\n",
            "Epoch:  48 , Batch:  49 , loss avg over log interval:  3.790121603012085\n",
            "saving model\n",
            "Epoch:  48 , Batch:  74 , loss avg over log interval:  3.791868896484375\n",
            "Epoch:  48 , Batch:  99 , loss avg over log interval:  3.774949378967285\n",
            "saving model\n",
            "Epoch:  48 , Batch:  124 , loss avg over log interval:  3.777653150558472\n",
            "saving model\n",
            "Epoch:  48 , avg total loss:  3.7817771500104094\n",
            "iter   0\n",
            "accuracy so far =  0.7890625\n",
            "Avg Validation Loss:  0.029981778837673764\n",
            "Accuracy:  0.2477633741099142\n",
            "Epoch 48/99 Completed\n",
            "Epoch:  49 , Batch:  0 , loss avg over log interval:  3.7529561519622803\n",
            "Epoch:  49 , Batch:  24 , loss avg over log interval:  3.6247323989868163\n",
            "Epoch:  49 , Batch:  49 , loss avg over log interval:  3.780726099014282\n",
            "saving model\n",
            "Epoch:  49 , Batch:  74 , loss avg over log interval:  3.792705478668213\n",
            "Epoch:  49 , Batch:  99 , loss avg over log interval:  3.7765878009796143\n",
            "saving model\n",
            "Epoch:  49 , Batch:  124 , loss avg over log interval:  3.786172456741333\n",
            "saving model\n",
            "Epoch:  49 , avg total loss:  3.7825606293874245\n",
            "iter   0\n",
            "accuracy so far =  0.734375\n",
            "Avg Validation Loss:  0.029946590788895052\n",
            "Accuracy:  0.25013693627898487\n",
            "Epoch 49/99 Completed\n",
            "Epoch:  50 , Batch:  0 , loss avg over log interval:  3.8204171657562256\n",
            "Epoch:  50 , Batch:  24 , loss avg over log interval:  3.6262504482269287\n",
            "Epoch:  50 , Batch:  49 , loss avg over log interval:  3.794935998916626\n",
            "saving model\n",
            "Epoch:  50 , Batch:  74 , loss avg over log interval:  3.787344617843628\n",
            "Epoch:  50 , Batch:  99 , loss avg over log interval:  3.7821664905548094\n",
            "saving model\n",
            "Epoch:  50 , Batch:  124 , loss avg over log interval:  3.7839924621582033\n",
            "saving model\n",
            "Epoch:  50 , avg total loss:  3.78562164469941\n",
            "iter   0\n",
            "accuracy so far =  0.7109375\n",
            "Avg Validation Loss:  0.029922193433543246\n",
            "Accuracy:  0.24849370093116668\n",
            "Epoch 50/99 Completed\n",
            "Epoch:  51 , Batch:  0 , loss avg over log interval:  3.7574405670166016\n",
            "Epoch:  51 , Batch:  24 , loss avg over log interval:  3.6202665996551513\n",
            "Epoch:  51 , Batch:  49 , loss avg over log interval:  3.7773937511444093\n",
            "saving model\n",
            "Epoch:  51 , Batch:  74 , loss avg over log interval:  3.7788447093963624\n",
            "Epoch:  51 , Batch:  99 , loss avg over log interval:  3.770654878616333\n",
            "saving model\n",
            "Epoch:  51 , Batch:  124 , loss avg over log interval:  3.776009826660156\n",
            "saving model\n",
            "Epoch:  51 , avg total loss:  3.773730353133319\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.0298889669728623\n",
            "Accuracy:  0.25397115209056054\n",
            "Epoch 51/99 Completed\n",
            "Epoch:  52 , Batch:  0 , loss avg over log interval:  3.829092025756836\n",
            "Epoch:  52 , Batch:  24 , loss avg over log interval:  3.6312403869628906\n",
            "Epoch:  52 , Batch:  49 , loss avg over log interval:  3.7855107498168947\n",
            "saving model\n",
            "Epoch:  52 , Batch:  74 , loss avg over log interval:  3.7687703132629395\n",
            "Epoch:  52 , Batch:  99 , loss avg over log interval:  3.772880058288574\n",
            "saving model\n",
            "Epoch:  52 , Batch:  124 , loss avg over log interval:  3.7688176345825197\n",
            "saving model\n",
            "Epoch:  52 , avg total loss:  3.775170625072636\n",
            "iter   0\n",
            "accuracy so far =  0.7734375\n",
            "Avg Validation Loss:  0.029869908374091973\n",
            "Accuracy:  0.2557969691436918\n",
            "Epoch 52/99 Completed\n",
            "Epoch:  53 , Batch:  0 , loss avg over log interval:  3.8058583736419678\n",
            "Epoch:  53 , Batch:  24 , loss avg over log interval:  3.6206329250335694\n",
            "Epoch:  53 , Batch:  49 , loss avg over log interval:  3.78144136428833\n",
            "saving model\n",
            "Epoch:  53 , Batch:  74 , loss avg over log interval:  3.7762816524505616\n",
            "Epoch:  53 , Batch:  99 , loss avg over log interval:  3.7698923110961915\n",
            "saving model\n",
            "Epoch:  53 , Batch:  124 , loss avg over log interval:  3.774124641418457\n",
            "saving model\n",
            "Epoch:  53 , avg total loss:  3.7727994592222447\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.02986185080991602\n",
            "Accuracy:  0.2570750410808837\n",
            "Epoch 53/99 Completed\n",
            "Epoch:  54 , Batch:  0 , loss avg over log interval:  3.782994508743286\n",
            "Epoch:  54 , Batch:  24 , loss avg over log interval:  3.615578680038452\n",
            "Epoch:  54 , Batch:  49 , loss avg over log interval:  3.7689111614227295\n",
            "saving model\n",
            "Epoch:  54 , Batch:  74 , loss avg over log interval:  3.771332302093506\n",
            "Epoch:  54 , Batch:  99 , loss avg over log interval:  3.760847692489624\n",
            "saving model\n",
            "Epoch:  54 , Batch:  124 , loss avg over log interval:  3.7664735889434815\n",
            "saving model\n",
            "Epoch:  54 , avg total loss:  3.76717589816002\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.0298593880509033\n",
            "Accuracy:  0.25926602154464123\n",
            "Epoch 54/99 Completed\n",
            "Epoch:  55 , Batch:  0 , loss avg over log interval:  3.738381862640381\n",
            "Epoch:  55 , Batch:  24 , loss avg over log interval:  3.619873456954956\n",
            "Epoch:  55 , Batch:  49 , loss avg over log interval:  3.7790610504150393\n",
            "saving model\n",
            "Epoch:  55 , Batch:  74 , loss avg over log interval:  3.772564468383789\n",
            "Epoch:  55 , Batch:  99 , loss avg over log interval:  3.7749521923065186\n",
            "saving model\n",
            "Epoch:  55 , Batch:  124 , loss avg over log interval:  3.7650712299346925\n",
            "saving model\n",
            "Epoch:  55 , avg total loss:  3.7718654936307097\n",
            "iter   0\n",
            "accuracy so far =  0.6328125\n",
            "Avg Validation Loss:  0.02987341347980482\n",
            "Accuracy:  0.25415373379587364\n",
            "Epoch 55/99 Completed\n",
            "Epoch:  56 , Batch:  0 , loss avg over log interval:  3.7689220905303955\n",
            "Epoch:  56 , Batch:  24 , loss avg over log interval:  3.6172040462493897\n",
            "Epoch:  56 , Batch:  49 , loss avg over log interval:  3.774265909194946\n",
            "saving model\n",
            "Epoch:  56 , Batch:  74 , loss avg over log interval:  3.7664829444885255\n",
            "Epoch:  56 , Batch:  99 , loss avg over log interval:  3.7621727657318114\n",
            "saving model\n",
            "Epoch:  56 , Batch:  124 , loss avg over log interval:  3.767259159088135\n",
            "saving model\n",
            "Epoch:  56 , avg total loss:  3.7683065672443337\n",
            "iter   0\n",
            "accuracy so far =  0.6640625\n",
            "Avg Validation Loss:  0.029822935822107113\n",
            "Accuracy:  0.2616395837137119\n",
            "Epoch 56/99 Completed\n",
            "Epoch:  57 , Batch:  0 , loss avg over log interval:  3.7269723415374756\n",
            "Epoch:  57 , Batch:  24 , loss avg over log interval:  3.624518461227417\n",
            "Epoch:  57 , Batch:  49 , loss avg over log interval:  3.762912769317627\n",
            "saving model\n",
            "Epoch:  57 , Batch:  74 , loss avg over log interval:  3.7697185039520265\n",
            "Epoch:  57 , Batch:  99 , loss avg over log interval:  3.7618189334869383\n",
            "saving model\n",
            "Epoch:  57 , Batch:  124 , loss avg over log interval:  3.754381980895996\n",
            "saving model\n",
            "Epoch:  57 , avg total loss:  3.764899840093639\n",
            "iter   0\n",
            "accuracy so far =  0.671875\n",
            "Avg Validation Loss:  0.02980093575533842\n",
            "Accuracy:  0.2641957275880957\n",
            "Epoch 57/99 Completed\n",
            "Epoch:  58 , Batch:  0 , loss avg over log interval:  3.7422800064086914\n",
            "Epoch:  58 , Batch:  24 , loss avg over log interval:  3.614562301635742\n",
            "Epoch:  58 , Batch:  49 , loss avg over log interval:  3.764920644760132\n",
            "saving model\n",
            "Epoch:  58 , Batch:  74 , loss avg over log interval:  3.7632911300659178\n",
            "Epoch:  58 , Batch:  99 , loss avg over log interval:  3.753230218887329\n",
            "saving model\n",
            "Epoch:  58 , Batch:  124 , loss avg over log interval:  3.762912540435791\n",
            "saving model\n",
            "Epoch:  58 , avg total loss:  3.7631295135576432\n",
            "iter   0\n",
            "accuracy so far =  0.7265625\n",
            "Avg Validation Loss:  0.029789607499188613\n",
            "Accuracy:  0.2638305641774694\n",
            "Epoch 58/99 Completed\n",
            "Epoch:  59 , Batch:  0 , loss avg over log interval:  3.767383098602295\n",
            "Epoch:  59 , Batch:  24 , loss avg over log interval:  3.601477918624878\n",
            "Epoch:  59 , Batch:  49 , loss avg over log interval:  3.7661119556427\n",
            "saving model\n",
            "Epoch:  59 , Batch:  74 , loss avg over log interval:  3.7687557315826417\n",
            "Epoch:  59 , Batch:  99 , loss avg over log interval:  3.7636678218841553\n",
            "saving model\n",
            "saving model\n",
            "Epoch:  59 , avg total loss:  3.7589605099534333\n",
            "iter   0\n",
            "accuracy so far =  0.6875\n",
            "Avg Validation Loss:  0.029748143648304644\n",
            "Accuracy:  0.26967317874748953\n",
            "Epoch 59/99 Completed\n",
            "Epoch:  60 , Batch:  0 , loss avg over log interval:  3.7023699283599854\n",
            "Epoch:  60 , Batch:  24 , loss avg over log interval:  3.6126040840148925\n",
            "Epoch:  60 , Batch:  49 , loss avg over log interval:  3.7650067710876467\n",
            "saving model\n",
            "Epoch:  60 , Batch:  74 , loss avg over log interval:  3.760311098098755\n",
            "Epoch:  60 , Batch:  99 , loss avg over log interval:  3.744340867996216\n",
            "saving model\n",
            "Epoch:  60 , Batch:  124 , loss avg over log interval:  3.7528700733184817\n",
            "saving model\n",
            "Epoch:  60 , avg total loss:  3.758062050767141\n",
            "iter   0\n",
            "accuracy so far =  0.6875\n",
            "Avg Validation Loss:  0.029737918203234435\n",
            "Accuracy:  0.2736899762643783\n",
            "Epoch 60/99 Completed\n",
            "Epoch:  61 , Batch:  0 , loss avg over log interval:  3.7512295246124268\n",
            "Epoch:  61 , Batch:  24 , loss avg over log interval:  3.608712148666382\n",
            "Epoch:  61 , Batch:  49 , loss avg over log interval:  3.7547364234924316\n",
            "saving model\n",
            "Epoch:  61 , Batch:  74 , loss avg over log interval:  3.755462589263916\n",
            "Epoch:  61 , Batch:  99 , loss avg over log interval:  3.758151788711548\n",
            "saving model\n",
            "Epoch:  61 , Batch:  124 , loss avg over log interval:  3.750302028656006\n",
            "saving model\n",
            "Epoch:  61 , avg total loss:  3.7564070665673035\n",
            "iter   0\n",
            "accuracy so far =  0.6484375\n",
            "Avg Validation Loss:  0.02970088557733853\n",
            "Accuracy:  0.28975716633193355\n",
            "Epoch 61/99 Completed\n",
            "Epoch:  62 , Batch:  0 , loss avg over log interval:  3.7282638549804688\n",
            "Epoch:  62 , Batch:  24 , loss avg over log interval:  3.6059388446807863\n",
            "Epoch:  62 , Batch:  49 , loss avg over log interval:  3.7545245361328123\n",
            "saving model\n",
            "Epoch:  62 , Batch:  74 , loss avg over log interval:  3.75889347076416\n",
            "Epoch:  62 , Batch:  99 , loss avg over log interval:  3.743422899246216\n",
            "saving model\n",
            "Epoch:  62 , Batch:  124 , loss avg over log interval:  3.752134838104248\n",
            "saving model\n",
            "Epoch:  62 , avg total loss:  3.7529565716442996\n",
            "iter   0\n",
            "accuracy so far =  0.671875\n",
            "Avg Validation Loss:  0.029683407366830807\n",
            "Accuracy:  0.2966952711338324\n",
            "Epoch 62/99 Completed\n",
            "Epoch:  63 , Batch:  0 , loss avg over log interval:  3.729346752166748\n",
            "Epoch:  63 , Batch:  24 , loss avg over log interval:  3.6026735401153562\n",
            "Epoch:  63 , Batch:  49 , loss avg over log interval:  3.7474918460845945\n",
            "saving model\n",
            "Epoch:  63 , Batch:  74 , loss avg over log interval:  3.7506802082061768\n",
            "Epoch:  63 , Batch:  99 , loss avg over log interval:  3.7426624965667723\n",
            "saving model\n",
            "Epoch:  63 , Batch:  124 , loss avg over log interval:  3.7445431900024415\n",
            "saving model\n",
            "Epoch:  63 , avg total loss:  3.747315658281927\n",
            "iter   0\n",
            "accuracy so far =  0.640625\n",
            "Avg Validation Loss:  0.0296572072675286\n",
            "Accuracy:  0.3007120686507212\n",
            "Epoch 63/99 Completed\n",
            "Epoch:  64 , Batch:  0 , loss avg over log interval:  3.7094802856445312\n",
            "Epoch:  64 , Batch:  24 , loss avg over log interval:  3.6070074081420898\n",
            "Epoch:  64 , Batch:  49 , loss avg over log interval:  3.748293943405151\n",
            "saving model\n",
            "Epoch:  64 , Batch:  74 , loss avg over log interval:  3.749125452041626\n",
            "Epoch:  64 , Batch:  99 , loss avg over log interval:  3.7406665229797365\n",
            "saving model\n",
            "Epoch:  64 , Batch:  124 , loss avg over log interval:  3.743196029663086\n",
            "saving model\n",
            "Epoch:  64 , avg total loss:  3.7476398667244064\n",
            "iter   0\n",
            "accuracy so far =  0.6171875\n",
            "Avg Validation Loss:  0.029622467456126008\n",
            "Accuracy:  0.3034507942304181\n",
            "Epoch 64/99 Completed\n",
            "Epoch:  65 , Batch:  0 , loss avg over log interval:  3.7189950942993164\n",
            "Epoch:  65 , Batch:  24 , loss avg over log interval:  3.6049223518371583\n",
            "Epoch:  65 , Batch:  49 , loss avg over log interval:  3.752347993850708\n",
            "saving model\n",
            "Epoch:  65 , Batch:  74 , loss avg over log interval:  3.7544079971313478\n",
            "Epoch:  65 , Batch:  99 , loss avg over log interval:  3.7334836769104003\n",
            "saving model\n",
            "Epoch:  65 , Batch:  124 , loss avg over log interval:  3.7390161037445067\n",
            "saving model\n",
            "Epoch:  65 , avg total loss:  3.747172283799681\n",
            "iter   0\n",
            "accuracy so far =  0.6640625\n",
            "Avg Validation Loss:  0.029602787845953552\n",
            "Accuracy:  0.3041811210516706\n",
            "Epoch 65/99 Completed\n",
            "Epoch:  66 , Batch:  0 , loss avg over log interval:  3.6835668087005615\n",
            "Epoch:  66 , Batch:  24 , loss avg over log interval:  3.599806547164917\n",
            "Epoch:  66 , Batch:  49 , loss avg over log interval:  3.7529882526397706\n",
            "saving model\n",
            "Epoch:  66 , Batch:  74 , loss avg over log interval:  3.7504443073272706\n",
            "Epoch:  66 , Batch:  99 , loss avg over log interval:  3.7288958740234377\n",
            "saving model\n",
            "Epoch:  66 , Batch:  124 , loss avg over log interval:  3.7410635566711425\n",
            "saving model\n",
            "Epoch:  66 , avg total loss:  3.745597385380366\n",
            "iter   0\n",
            "accuracy so far =  0.7109375\n",
            "Avg Validation Loss:  0.029565581227167258\n",
            "Accuracy:  0.3100237356216907\n",
            "Epoch 66/99 Completed\n",
            "Epoch:  67 , Batch:  0 , loss avg over log interval:  3.7145819664001465\n",
            "Epoch:  67 , Batch:  24 , loss avg over log interval:  3.5958646965026855\n",
            "Epoch:  67 , Batch:  49 , loss avg over log interval:  3.7324666023254394\n",
            "saving model\n",
            "Epoch:  67 , Batch:  74 , loss avg over log interval:  3.7463366985321045\n",
            "Epoch:  67 , Batch:  99 , loss avg over log interval:  3.74488787651062\n",
            "saving model\n",
            "Epoch:  67 , Batch:  124 , loss avg over log interval:  3.7373149299621584\n",
            "saving model\n",
            "Epoch:  67 , avg total loss:  3.740377860526516\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.029516131681574943\n",
            "Accuracy:  0.3156837684863977\n",
            "Epoch 67/99 Completed\n",
            "Epoch:  68 , Batch:  0 , loss avg over log interval:  3.7729365825653076\n",
            "Epoch:  68 , Batch:  24 , loss avg over log interval:  3.5876920509338377\n",
            "Epoch:  68 , Batch:  49 , loss avg over log interval:  3.75088116645813\n",
            "saving model\n",
            "Epoch:  68 , Batch:  74 , loss avg over log interval:  3.7304495334625245\n",
            "Epoch:  68 , Batch:  99 , loss avg over log interval:  3.7339426040649415\n",
            "saving model\n",
            "Epoch:  68 , Batch:  124 , loss avg over log interval:  3.7481690216064454\n",
            "saving model\n",
            "Epoch:  68 , avg total loss:  3.738956046431032\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.029531360390805755\n",
            "Accuracy:  0.31239729779076136\n",
            "Epoch 68/99 Completed\n",
            "Epoch:  69 , Batch:  0 , loss avg over log interval:  3.711488723754883\n",
            "Epoch:  69 , Batch:  24 , loss avg over log interval:  3.589539785385132\n",
            "Epoch:  69 , Batch:  49 , loss avg over log interval:  3.750192928314209\n",
            "saving model\n",
            "Epoch:  69 , Batch:  74 , loss avg over log interval:  3.747046413421631\n",
            "Epoch:  69 , Batch:  99 , loss avg over log interval:  3.727537488937378\n",
            "saving model\n",
            "Epoch:  69 , Batch:  124 , loss avg over log interval:  3.7329729270935057\n",
            "saving model\n",
            "Epoch:  69 , avg total loss:  3.7399844649719864\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.02952687771232846\n",
            "Accuracy:  0.3182399123607815\n",
            "Epoch 69/99 Completed\n",
            "Epoch:  70 , Batch:  0 , loss avg over log interval:  3.734724283218384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDmKw9pMH3NJ"
      },
      "source": [
        "# Resume Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e2ac1ce20b5e41208342e5a917726d4e",
            "558faa8cc4124de49c3a432e37c04007",
            "604efc3f04374c5fb6d42b7c7168a035",
            "0c11d17f29ab4864845384c6862f629f",
            "e3811e599c794585aded5b04075a8109",
            "790b18b1f19a494bb6bc15cfb14f4e39",
            "425029eadae5419b94cda4c64d988d75",
            "4767defab70242f799e31ec3d7d71b41"
          ]
        },
        "id": "0UlgNih0H2DD",
        "outputId": "db37fc16-1ac4-452b-ac3b-8451daa64af6"
      },
      "source": [
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# initialize weights\n",
        "# for m in spatial.modules():\n",
        "#     if isinstance(m, torch.nn.Linear):\n",
        "#         torch.nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "#         torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 100\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "# Load params\n",
        "last_epoch = 69\n",
        "\n",
        "# load data\n",
        "network_path = EPOCH_SAVE_PREFIX + 'spatial_epoch{}'.format(last_epoch)\n",
        "checkpoint = torch.load(network_path)\n",
        "spatial.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "last_epoch = checkpoint['epoch']\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "accuracy_list = checkpoint['accuracy_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(last_epoch + 1, num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Adjust Learning Rate\n",
        "    # if epoch == 8 or epoch == 13:\n",
        "    #     pass\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': spatial.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2ac1ce20b5e41208342e5a917726d4e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  9 , Batch:  0 , loss avg over log interval:  3.579054117202759\n",
            "Epoch:  9 , Batch:  99 , loss avg over log interval:  3.5460293793678286\n",
            "Epoch:  9 , Batch:  199 , loss avg over log interval:  3.5823871088027954\n",
            "saving model\n",
            "Epoch:  9 , Batch:  299 , loss avg over log interval:  3.5742266011238097\n",
            "Epoch:  9 , Batch:  399 , loss avg over log interval:  3.578859972953796\n",
            "Epoch:  9 , Batch:  499 , loss avg over log interval:  3.5777490186691283\n",
            "saving model\n",
            "Epoch:  9 , Batch:  599 , loss avg over log interval:  3.579861807823181\n",
            "Epoch:  9 , Batch:  699 , loss avg over log interval:  3.5729906296730043\n",
            "saving model\n",
            "Epoch:  9 , Batch:  799 , loss avg over log interval:  3.57385466337204\n",
            "Epoch:  9 , Batch:  899 , loss avg over log interval:  3.5813414573669435\n",
            "Epoch:  9 , Batch:  999 , loss avg over log interval:  3.576751308441162\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1099 , loss avg over log interval:  3.5745735216140746\n",
            "Epoch:  9 , Batch:  1199 , loss avg over log interval:  3.5685772466659547\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1299 , loss avg over log interval:  3.577754440307617\n",
            "Epoch:  9 , Batch:  1399 , loss avg over log interval:  3.5721950912475586\n",
            "Epoch:  9 , Batch:  1499 , loss avg over log interval:  3.5717737030982972\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1599 , loss avg over log interval:  3.578251359462738\n",
            "Epoch:  9 , Batch:  1699 , loss avg over log interval:  3.5745250725746156\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1799 , loss avg over log interval:  3.5757372522354127\n",
            "Epoch:  9 , Batch:  1899 , loss avg over log interval:  3.567928261756897\n",
            "Epoch:  9 , Batch:  1999 , loss avg over log interval:  3.584934277534485\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2099 , loss avg over log interval:  3.577485022544861\n",
            "Epoch:  9 , Batch:  2199 , loss avg over log interval:  3.5743262720108033\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2299 , loss avg over log interval:  3.5728429841995237\n",
            "Epoch:  9 , Batch:  2399 , loss avg over log interval:  3.576960034370422\n",
            "Epoch:  9 , Batch:  2499 , loss avg over log interval:  3.5769550704956057\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2599 , loss avg over log interval:  3.571277866363525\n",
            "Epoch:  9 , Batch:  2699 , loss avg over log interval:  3.5720484018325807\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2799 , loss avg over log interval:  3.5723149943351746\n",
            "Epoch:  9 , Batch:  2899 , loss avg over log interval:  3.5673414778709414\n",
            "Epoch:  9 , Batch:  2999 , loss avg over log interval:  3.5718661737442017\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3099 , loss avg over log interval:  3.5671669363975527\n",
            "Epoch:  9 , Batch:  3199 , loss avg over log interval:  3.5618692779541017\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3299 , loss avg over log interval:  3.5713111758232117\n",
            "Epoch:  9 , Batch:  3399 , loss avg over log interval:  3.575955722332001\n",
            "Epoch:  9 , Batch:  3499 , loss avg over log interval:  3.5696138167381286\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3599 , loss avg over log interval:  3.569198315143585\n",
            "Epoch:  9 , Batch:  3699 , loss avg over log interval:  3.5705218291282654\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3799 , loss avg over log interval:  3.5734462451934816\n",
            "Epoch:  9 , avg total loss:  3.5741825942032306\n",
            "iter   0\n",
            "accuracy so far =  0.9765625\n",
            "iter   100\n",
            "accuracy so far =  0.5340346534653465\n",
            "iter   200\n",
            "accuracy so far =  0.5257307213930348\n",
            "iter   300\n",
            "accuracy so far =  0.5087728405315615\n",
            "iter   400\n",
            "accuracy so far =  0.45086502493765584\n",
            "iter   500\n",
            "accuracy so far =  0.39622317864271456\n",
            "iter   600\n",
            "accuracy so far =  0.43774698419301167\n",
            "iter   700\n",
            "accuracy so far =  0.48912268188302427\n",
            "iter   800\n",
            "accuracy so far =  0.5168734394506866\n",
            "iter   900\n",
            "accuracy so far =  0.5080119311875694\n",
            "iter   1000\n",
            "accuracy so far =  0.503894542957043\n",
            "iter   1100\n",
            "accuracy so far =  0.5036401566757494\n",
            "Avg Validation Loss:  0.028279996895338323\n",
            "Accuracy:  0.49671250909342846\n",
            "Epoch 9/49 Completed\n",
            "Epoch:  10 , Batch:  0 , loss avg over log interval:  3.6594810485839844\n",
            "Epoch:  10 , Batch:  99 , loss avg over log interval:  3.534887034893036\n",
            "Epoch:  10 , Batch:  199 , loss avg over log interval:  3.560631122589111\n",
            "saving model\n",
            "Epoch:  10 , Batch:  299 , loss avg over log interval:  3.5786735010147095\n",
            "Epoch:  10 , Batch:  399 , loss avg over log interval:  3.570725555419922\n",
            "Epoch:  10 , Batch:  499 , loss avg over log interval:  3.5668704223632814\n",
            "saving model\n",
            "Epoch:  10 , Batch:  599 , loss avg over log interval:  3.563460876941681\n",
            "Epoch:  10 , Batch:  699 , loss avg over log interval:  3.5732044100761415\n",
            "saving model\n",
            "Epoch:  10 , Batch:  799 , loss avg over log interval:  3.564046459197998\n",
            "Epoch:  10 , Batch:  899 , loss avg over log interval:  3.559336869716644\n",
            "Epoch:  10 , Batch:  999 , loss avg over log interval:  3.561542465686798\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1099 , loss avg over log interval:  3.572560291290283\n",
            "Epoch:  10 , Batch:  1199 , loss avg over log interval:  3.5655527210235594\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1299 , loss avg over log interval:  3.5702772068977358\n",
            "Epoch:  10 , Batch:  1399 , loss avg over log interval:  3.563330955505371\n",
            "Epoch:  10 , Batch:  1499 , loss avg over log interval:  3.570376570224762\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1599 , loss avg over log interval:  3.5713502097129823\n",
            "Epoch:  10 , Batch:  1699 , loss avg over log interval:  3.567695467472076\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1799 , loss avg over log interval:  3.5666957116127014\n",
            "Epoch:  10 , Batch:  1899 , loss avg over log interval:  3.5684423208236695\n",
            "Epoch:  10 , Batch:  1999 , loss avg over log interval:  3.5663747429847716\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2099 , loss avg over log interval:  3.5645128321647643\n",
            "Epoch:  10 , Batch:  2199 , loss avg over log interval:  3.5729643368721007\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2299 , loss avg over log interval:  3.562355363368988\n",
            "Epoch:  10 , Batch:  2399 , loss avg over log interval:  3.567446722984314\n",
            "Epoch:  10 , Batch:  2499 , loss avg over log interval:  3.5595063948631287\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2599 , loss avg over log interval:  3.564383125305176\n",
            "Epoch:  10 , Batch:  2699 , loss avg over log interval:  3.559916534423828\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2799 , loss avg over log interval:  3.5679066967964173\n",
            "Epoch:  10 , Batch:  2899 , loss avg over log interval:  3.5615393853187562\n",
            "Epoch:  10 , Batch:  2999 , loss avg over log interval:  3.56071852684021\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3099 , loss avg over log interval:  3.568175437450409\n",
            "Epoch:  10 , Batch:  3199 , loss avg over log interval:  3.5698301005363464\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3299 , loss avg over log interval:  3.556127848625183\n",
            "Epoch:  10 , Batch:  3399 , loss avg over log interval:  3.5617884612083435\n",
            "Epoch:  10 , Batch:  3499 , loss avg over log interval:  3.559564802646637\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3599 , loss avg over log interval:  3.5699443101882933\n",
            "Epoch:  10 , Batch:  3699 , loss avg over log interval:  3.558623332977295\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3799 , loss avg over log interval:  3.5667728781700134\n",
            "Epoch:  10 , avg total loss:  3.565968542772589\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "iter   100\n",
            "accuracy so far =  0.5010829207920792\n",
            "iter   200\n",
            "accuracy so far =  0.5099113805970149\n",
            "iter   300\n",
            "accuracy so far =  0.506047549833887\n",
            "iter   400\n",
            "accuracy so far =  0.4458969763092269\n",
            "iter   500\n",
            "accuracy so far =  0.3964726796407186\n",
            "iter   600\n",
            "accuracy so far =  0.43626507903494177\n",
            "iter   700\n",
            "accuracy so far =  0.49089470399429386\n",
            "iter   800\n",
            "accuracy so far =  0.5203359082397003\n",
            "iter   900\n",
            "accuracy so far =  0.5162666481687015\n",
            "iter   1000\n",
            "accuracy so far =  0.512268981018981\n",
            "iter   1100\n",
            "accuracy so far =  0.5127370004541326\n",
            "Avg Validation Loss:  0.02823190674715891\n",
            "Accuracy:  0.5054075588041709\n",
            "Epoch 10/49 Completed\n",
            "Epoch:  11 , Batch:  0 , loss avg over log interval:  3.545201539993286\n",
            "Epoch:  11 , Batch:  99 , loss avg over log interval:  3.5204057192802427\n",
            "Epoch:  11 , Batch:  199 , loss avg over log interval:  3.5558080220222474\n",
            "saving model\n",
            "Epoch:  11 , Batch:  299 , loss avg over log interval:  3.5599300408363344\n",
            "Epoch:  11 , Batch:  399 , loss avg over log interval:  3.562694766521454\n",
            "Epoch:  11 , Batch:  499 , loss avg over log interval:  3.55555721282959\n",
            "saving model\n",
            "Epoch:  11 , Batch:  599 , loss avg over log interval:  3.5604484820365907\n",
            "Epoch:  11 , Batch:  699 , loss avg over log interval:  3.5552010226249693\n",
            "saving model\n",
            "Epoch:  11 , Batch:  799 , loss avg over log interval:  3.560649333000183\n",
            "Epoch:  11 , Batch:  899 , loss avg over log interval:  3.56130811214447\n",
            "Epoch:  11 , Batch:  999 , loss avg over log interval:  3.5550798988342285\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1099 , loss avg over log interval:  3.55528270483017\n",
            "Epoch:  11 , Batch:  1199 , loss avg over log interval:  3.567438428401947\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1299 , loss avg over log interval:  3.5572629570961\n",
            "Epoch:  11 , Batch:  1399 , loss avg over log interval:  3.5556547331809996\n",
            "Epoch:  11 , Batch:  1499 , loss avg over log interval:  3.5591497564315797\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1599 , loss avg over log interval:  3.563854157924652\n",
            "Epoch:  11 , Batch:  1699 , loss avg over log interval:  3.5550047087669374\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1799 , loss avg over log interval:  3.5547358536720277\n",
            "Epoch:  11 , Batch:  1899 , loss avg over log interval:  3.5626550936698913\n",
            "Epoch:  11 , Batch:  1999 , loss avg over log interval:  3.555945646762848\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2099 , loss avg over log interval:  3.5584344935417174\n",
            "Epoch:  11 , Batch:  2199 , loss avg over log interval:  3.556195936203003\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2299 , loss avg over log interval:  3.5598151588439944\n",
            "Epoch:  11 , Batch:  2399 , loss avg over log interval:  3.5551564145088195\n",
            "Epoch:  11 , Batch:  2499 , loss avg over log interval:  3.5538482809066774\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2599 , loss avg over log interval:  3.5663298058509825\n",
            "Epoch:  11 , Batch:  2699 , loss avg over log interval:  3.5543218898773192\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2799 , loss avg over log interval:  3.5483792662620544\n",
            "Epoch:  11 , Batch:  2899 , loss avg over log interval:  3.5596454095840455\n",
            "Epoch:  11 , Batch:  2999 , loss avg over log interval:  3.5616452145576476\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3099 , loss avg over log interval:  3.553210859298706\n",
            "Epoch:  11 , Batch:  3199 , loss avg over log interval:  3.5537309050559998\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3299 , loss avg over log interval:  3.556489462852478\n",
            "Epoch:  11 , Batch:  3399 , loss avg over log interval:  3.5549196076393126\n",
            "Epoch:  11 , Batch:  3499 , loss avg over log interval:  3.5470906352996825\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3599 , loss avg over log interval:  3.5557191348075867\n",
            "Epoch:  11 , Batch:  3699 , loss avg over log interval:  3.5440936303138733\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3799 , loss avg over log interval:  3.546159794330597\n",
            "Epoch:  11 , avg total loss:  3.556547733444079\n",
            "iter   0\n",
            "accuracy so far =  1.0\n",
            "iter   100\n",
            "accuracy so far =  0.5326423267326733\n",
            "iter   200\n",
            "accuracy so far =  0.5050528606965174\n",
            "iter   300\n",
            "accuracy so far =  0.5082018272425249\n",
            "iter   400\n",
            "accuracy so far =  0.4494427992518703\n",
            "iter   500\n",
            "accuracy so far =  0.39458582834331335\n",
            "iter   600\n",
            "accuracy so far =  0.42543677204658903\n",
            "iter   700\n",
            "accuracy so far =  0.4794155670470756\n",
            "iter   800\n",
            "accuracy so far =  0.505500936329588\n",
            "iter   900\n",
            "accuracy so far =  0.5127635960044395\n",
            "iter   1000\n",
            "accuracy so far =  0.5056037712287712\n",
            "iter   1100\n",
            "accuracy so far =  0.5030512034514079\n",
            "Avg Validation Loss:  0.028270143950018953\n",
            "Accuracy:  0.496428447708456\n",
            "Epoch 11/49 Completed\n",
            "Epoch:  12 , Batch:  0 , loss avg over log interval:  3.593905448913574\n",
            "Epoch:  12 , Batch:  99 , loss avg over log interval:  3.521117215156555\n",
            "Epoch:  12 , Batch:  199 , loss avg over log interval:  3.552168846130371\n",
            "saving model\n",
            "Epoch:  12 , Batch:  299 , loss avg over log interval:  3.5547372937202453\n",
            "Epoch:  12 , Batch:  399 , loss avg over log interval:  3.550812337398529\n",
            "Epoch:  12 , Batch:  499 , loss avg over log interval:  3.5568406987190246\n",
            "saving model\n",
            "Epoch:  12 , Batch:  599 , loss avg over log interval:  3.5536263036727904\n",
            "Epoch:  12 , Batch:  699 , loss avg over log interval:  3.548257262706757\n",
            "saving model\n",
            "Epoch:  12 , Batch:  799 , loss avg over log interval:  3.5533126187324524\n",
            "Epoch:  12 , Batch:  899 , loss avg over log interval:  3.556446475982666\n",
            "Epoch:  12 , Batch:  999 , loss avg over log interval:  3.54851273059845\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1099 , loss avg over log interval:  3.5536370778083803\n",
            "Epoch:  12 , Batch:  1199 , loss avg over log interval:  3.552349154949188\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1299 , loss avg over log interval:  3.557411675453186\n",
            "Epoch:  12 , Batch:  1399 , loss avg over log interval:  3.5463144111633302\n",
            "Epoch:  12 , Batch:  1499 , loss avg over log interval:  3.5458537459373476\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1599 , loss avg over log interval:  3.553555226325989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy2dqXCRNr7g"
      },
      "source": [
        "# Calculate Accuracy of a Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Nbs6zlNy_0",
        "outputId": "13228753-b908-4e29-b156-c53cdec81fb3"
      },
      "source": [
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Load params\n",
        "last_epoch = 69\n",
        "\n",
        "# load data\n",
        "network_path = EPOCH_SAVE_PREFIX + 'spatial_epoch{}'.format(last_epoch)\n",
        "checkpoint = torch.load(network_path)\n",
        "spatial.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "last_epoch = checkpoint['epoch']\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "iter   10\n",
            "accuracy so far =  1.0\n",
            "Avg Validation Loss:  0.0002464993757317368\n",
            "Accuracy:  0.009755083659542037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBlIZRcTZIOZ"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlPLWagHAYEz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "outputId": "129662b9-6a9f-4e93-c1eb-f31ddfe7515e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# Load params\n",
        "last_epoch = 69\n",
        "\n",
        "# load data\n",
        "network_path = EPOCH_SAVE_PREFIX + 'spatial_epoch{}'.format(last_epoch)\n",
        "checkpoint = torch.load(network_path)\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "accuracy_list = checkpoint['accuracy_lsit']\n",
        "epoch_list = np.arange(last_epoch+1)\n",
        "\n",
        "\n",
        "# plots\n",
        "fig = plt.figure()\n",
        "plt.plot(epoch_loss_list, color='blue')\n",
        "plt.legend(['Spatial Train Loss'], loc='upper right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Total Loss')\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(test_loss_list, color='green')\n",
        "plt.legend(['Spatial Validation Loss'], loc='upper right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Total Loss')\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(accuracy_list, color='red')\n",
        "plt.legend(['Spatial Validation Accuracy'], loc='lower right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}