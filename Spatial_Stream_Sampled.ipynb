{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spatial_Stream_Sampled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2ac1ce20b5e41208342e5a917726d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_558faa8cc4124de49c3a432e37c04007",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_604efc3f04374c5fb6d42b7c7168a035",
              "IPY_MODEL_0c11d17f29ab4864845384c6862f629f"
            ]
          }
        },
        "558faa8cc4124de49c3a432e37c04007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "604efc3f04374c5fb6d42b7c7168a035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e3811e599c794585aded5b04075a8109",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_790b18b1f19a494bb6bc15cfb14f4e39"
          }
        },
        "0c11d17f29ab4864845384c6862f629f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_425029eadae5419b94cda4c64d988d75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:15&lt;00:00, 6.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4767defab70242f799e31ec3d7d71b41"
          }
        },
        "e3811e599c794585aded5b04075a8109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "790b18b1f19a494bb6bc15cfb14f4e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "425029eadae5419b94cda4c64d988d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4767defab70242f799e31ec3d7d71b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgqAhYHvNg2"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA580dbFbyEn",
        "outputId": "cc72a8d7-8b70-4442-c984-267b7b882466"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 12 06:11:42 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOC44nKYDOn8"
      },
      "source": [
        "# Run this command once and restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZffaB6C7Z7",
        "outputId": "e491cce7-7030-465d-92b2-6c0b8ac099a6"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n",
            "\u001b[K     |████████████████████████████████| 36.9MB 138kB/s \n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-8.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwpGXLdtuq8i"
      },
      "source": [
        "# Mount drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6nsoL9Kuqil",
        "outputId": "10e4d87c-da0a-4e71-e2e3-8e3d54cb7140"
      },
      "source": [
        "import os\n",
        "import io\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive\n",
        "DRIVE_MOUNT='/content/drive'\n",
        "\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "\n",
        "# create folder to write data to\n",
        "DATA_FOLDER = os.path.join(DRIVE_MOUNT, 'Shared drives', 'CIS680 Final Project', 'data')\n",
        "TRAIN_FOLDER = os.path.join(DATA_FOLDER, 'dataset_1', 'train')\n",
        "TEST_FOLDER = os.path.join(DATA_FOLDER, 'dataset_1', 'test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6FpL-ddpSI"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8J0AEPhdqg8"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "# from dataset import *\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class SpatialStream(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 device='cuda',\n",
        "                 num_classes=51,\n",
        "                 dropout_probability=0.5,\n",
        "                 train_resnet=True):\n",
        "\n",
        "        # Initialize the stream layers\n",
        "        super(SpatialStream, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Spatial Backbone\n",
        "        self.spatial = models.resnet50(pretrained=True)\n",
        "        for param in self.spatial.parameters():\n",
        "            param.requires_grad = train_resnet  # False: Freezes the weights of the pre-trained model\n",
        "\n",
        "        # Add to Spatial Backbone\n",
        "        self.spatial.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Linear(1024, self.num_classes),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Softmax())\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.spatial(X)\n",
        "\n",
        "    def compute_loss(self, output, labels):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # labels = torch.tensor(labels)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        return loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q86rcNdPQNL0"
      },
      "source": [
        "# Cache data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeWp2LAFp8CA",
        "outputId": "740a2d76-6185-4eae-adda-4ee50a9ce762"
      },
      "source": [
        "data_train = []\r\n",
        "data_test = []\r\n",
        "for iter in range(b_train):\r\n",
        "  data_train.append(torch.load(TRAIN_FOLDER + '/train_b{}.pt'.format(iter)))\r\n",
        "  if iter%5==0:\r\n",
        "    print(iter)\r\n",
        "for iter in range(b_test):\r\n",
        "  data_test.append(torch.load(TEST_FOLDER + '/test_b{}.pt'.format(iter)))\r\n",
        "  if iter%5==0:\r\n",
        "    print(iter)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n",
            "45\n",
            "50\n",
            "55\n",
            "60\n",
            "65\n",
            "70\n",
            "75\n",
            "80\n",
            "85\n",
            "90\n",
            "95\n",
            "100\n",
            "105\n",
            "110\n",
            "115\n",
            "120\n",
            "125\n",
            "130\n",
            "135\n",
            "140\n",
            "145\n",
            "0\n",
            "5\n",
            "10\n",
            "15\n",
            "20\n",
            "25\n",
            "30\n",
            "35\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pEvnrSVeftj"
      },
      "source": [
        "# Train & Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkzqmwzefQq"
      },
      "source": [
        "import torchvision.transforms as tf\n",
        "trans = tf.RandomHorizontalFlip()\n",
        "b_train = 146\n",
        "n_train = 18665\n",
        "b_test = 43\n",
        "n_test = 5477\n",
        "batch_size = 128\n",
        "\n",
        "def train(epoch):\n",
        "    \n",
        "    spatial.train()\n",
        "    counter = 0\n",
        "    train_loss = 0\n",
        "    log_interval = 25\n",
        "    save_interval = 50\n",
        "\n",
        "    epoch_loss = []\n",
        "    log_int_loss = 0\n",
        "    num_iter = 0\n",
        "\n",
        "    for iter in range(b_train):\n",
        "        data = data_train[iter]#torch.load(TRAIN_FOLDER + '/train_b{}.pt'.format(iter))\n",
        "\n",
        "        videos = data[\"videos\"].clone().squeeze(1).permute(0, 3, 1, 2)\n",
        "        videos = trans(videos)\n",
        "        labels = torch.tensor(data[\"labels\"].copy())\n",
        "\n",
        "        num_iter+=videos.shape[0]\n",
        "\n",
        "        videos = videos.type(torch.FloatTensor)\n",
        "        videos = videos.to(device)\n",
        "        # labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = spatial(videos)\n",
        "        output = output.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = spatial.compute_loss(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Logging Interval\n",
        "        log_int_loss += loss.item()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if counter == 0:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss)\n",
        "            train_loss_list.append(train_loss / num_iter)\n",
        "            train_counter.append(num_iter + epoch * n_train)\n",
        "            log_int_loss = 0\n",
        "        elif counter % log_interval == log_interval - 1:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss / log_interval)\n",
        "            train_loss_list.append(train_loss / num_iter)\n",
        "            train_counter.append(num_iter + epoch * n_train)\n",
        "            log_int_loss = 0\n",
        "\n",
        "        if counter % save_interval == save_interval - 1 or counter==b_train-1:\n",
        "            print('saving model')\n",
        "            save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch) + '_iter_' + str(counter))\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_total_loss_list': train_loss_list,\n",
        "                'epoch_total_loss_list': epoch_loss_list,\n",
        "                'test_loss_list': test_loss_list,\n",
        "                'train_counter': train_counter,\n",
        "                'accuracy_list': accuracy_list,\n",
        "                'model_state_dict': spatial.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, save_path)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "    epoch_loss_list.append(avg_loss)\n",
        "    print('Epoch: ', epoch, ', avg total loss: ', avg_loss)\n",
        "\n",
        "def test():\n",
        "    spatial.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Data Loop\n",
        "    with torch.no_grad():\n",
        "        for iter in range(b_test):\n",
        "            data = data_test[iter]#torch.load(TRAIN_FOLDER + '/test_b{}.pt'.format(iter))\n",
        "            videos = data[\"videos\"].clone().squeeze(1).permute(0, 3, 1, 2)\n",
        "            labels = torch.tensor(data[\"labels\"].copy())\n",
        "\n",
        "            videos = videos.type(torch.FloatTensor)\n",
        "            videos = videos.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = spatial(videos)\n",
        "            output = output.to(device)\n",
        "\n",
        "            # calculate losses\n",
        "            loss = spatial.compute_loss(output, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # calculate number of correct predictions in batch\n",
        "            correct += sum(torch.argmax(output,1) == labels).item()\n",
        "            if iter % 100 == 0:\n",
        "                print (\"iter  \", iter)\n",
        "                print(\"accuracy so far = \", correct / ((iter + 1) * len(labels)))\n",
        "\n",
        "    # Log\n",
        "    test_loss_list.append(test_loss / n_test)\n",
        "    accuracy = correct / n_test\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('Avg Validation Loss: ', test_loss / n_test)\n",
        "    print('Accuracy: ', accuracy)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxNfXCLLYcbW"
      },
      "source": [
        "# Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiW7i49DYbwc",
        "outputId": "263299f3-a2f6-4241-c1ec-6cd5893536d5"
      },
      "source": [
        "import numpy as np\n",
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# initialize weights\n",
        "# for m in spatial.modules():\n",
        "#     if isinstance(m, torch.nn.Linear):\n",
        "#         torch.nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "#         torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 100++\n",
        ";//+;*6333-++++++++++++++\n",
        "# Logging setup: train\n",
        "train_loss_list = []\n",
        "epoch_loss_list = []\n",
        "train_counter = []\n",
        "\n",
        "# Logging setup: test\n",
        "test_loss_list = []\n",
        "accuracy_list = []\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Adjust Learning Rate\n",
        "    # if epoch == 8 or epoch == 13:\n",
        "    #     pass\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': spatial.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 , Batch:  0 , loss avg over log interval:  3.9316935539245605\n",
            "Epoch:  0 , Batch:  24 , loss avg over log interval:  3.7745861434936523\n",
            "Epoch:  0 , Batch:  49 , loss avg over log interval:  3.9320147800445557\n",
            "saving model\n",
            "Epoch:  0 , Batch:  74 , loss avg over log interval:  3.931882858276367\n",
            "Epoch:  0 , Batch:  99 , loss avg over log interval:  3.9316771697998045\n",
            "saving model\n",
            "Epoch:  0 , Batch:  124 , loss avg over log interval:  3.93158164024353\n",
            "saving model\n",
            "Epoch:  0 , avg total loss:  3.9317470348044616\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.030866728922474964\n",
            "Accuracy:  0.04619317144422129\n",
            "Epoch 0/99 Completed\n",
            "Epoch:  1 , Batch:  0 , loss avg over log interval:  3.931469440460205\n",
            "Epoch:  1 , Batch:  24 , loss avg over log interval:  3.774281129837036\n",
            "Epoch:  1 , Batch:  49 , loss avg over log interval:  3.9311986637115477\n",
            "saving model\n",
            "Epoch:  1 , Batch:  74 , loss avg over log interval:  3.9310523414611818\n",
            "Epoch:  1 , Batch:  99 , loss avg over log interval:  3.930758457183838\n",
            "saving model\n",
            "Epoch:  1 , Batch:  124 , loss avg over log interval:  3.930634870529175\n",
            "saving model\n",
            "Epoch:  1 , avg total loss:  3.9309911140023845\n",
            "iter   0\n",
            "accuracy so far =  0.1875\n",
            "Avg Validation Loss:  0.03086497441072936\n",
            "Accuracy:  0.02556143874383787\n",
            "Epoch 1/99 Completed\n",
            "Epoch:  2 , Batch:  0 , loss avg over log interval:  3.93099308013916\n",
            "Epoch:  2 , Batch:  24 , loss avg over log interval:  3.7729117107391357\n",
            "Epoch:  2 , Batch:  49 , loss avg over log interval:  3.929643335342407\n",
            "saving model\n",
            "Epoch:  2 , Batch:  74 , loss avg over log interval:  3.9289041805267333\n",
            "Epoch:  2 , Batch:  99 , loss avg over log interval:  3.9273529624938965\n",
            "saving model\n",
            "Epoch:  2 , Batch:  124 , loss avg over log interval:  3.9266126441955564\n",
            "saving model\n",
            "Epoch:  2 , avg total loss:  3.927997674027534\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03086302222529967\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 2/99 Completed\n",
            "Epoch:  3 , Batch:  0 , loss avg over log interval:  3.9199559688568115\n",
            "Epoch:  3 , Batch:  24 , loss avg over log interval:  3.7629707622528077\n",
            "Epoch:  3 , Batch:  49 , loss avg over log interval:  3.914109983444214\n",
            "saving model\n",
            "Epoch:  3 , Batch:  74 , loss avg over log interval:  3.9035561752319334\n",
            "Epoch:  3 , Batch:  99 , loss avg over log interval:  3.900063591003418\n",
            "saving model\n",
            "Epoch:  3 , Batch:  124 , loss avg over log interval:  3.90510781288147\n",
            "saving model\n",
            "Epoch:  3 , avg total loss:  3.9080190429948782\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030859011160276093\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 3/99 Completed\n",
            "Epoch:  4 , Batch:  0 , loss avg over log interval:  3.896894693374634\n",
            "Epoch:  4 , Batch:  24 , loss avg over log interval:  3.741960573196411\n",
            "Epoch:  4 , Batch:  49 , loss avg over log interval:  3.9019147968292236\n",
            "saving model\n",
            "Epoch:  4 , Batch:  74 , loss avg over log interval:  3.8968633365631105\n",
            "Epoch:  4 , Batch:  99 , loss avg over log interval:  3.896348571777344\n",
            "saving model\n",
            "Epoch:  4 , Batch:  124 , loss avg over log interval:  3.8967878246307373\n",
            "saving model\n",
            "Epoch:  4 , avg total loss:  3.8983915799284636\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030853728166740046\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 4/99 Completed\n",
            "Epoch:  5 , Batch:  0 , loss avg over log interval:  3.903315544128418\n",
            "Epoch:  5 , Batch:  24 , loss avg over log interval:  3.7440699672698976\n",
            "Epoch:  5 , Batch:  49 , loss avg over log interval:  3.9021364974975588\n",
            "saving model\n",
            "Epoch:  5 , Batch:  74 , loss avg over log interval:  3.898153057098389\n",
            "Epoch:  5 , Batch:  99 , loss avg over log interval:  3.8920492267608644\n",
            "saving model\n",
            "Epoch:  5 , Batch:  124 , loss avg over log interval:  3.8976798248291016\n",
            "saving model\n",
            "Epoch:  5 , avg total loss:  3.8981620269278956\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030848127659032745\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 5/99 Completed\n",
            "Epoch:  6 , Batch:  0 , loss avg over log interval:  3.8849563598632812\n",
            "Epoch:  6 , Batch:  24 , loss avg over log interval:  3.741512041091919\n",
            "Epoch:  6 , Batch:  49 , loss avg over log interval:  3.898252458572388\n",
            "saving model\n",
            "Epoch:  6 , Batch:  74 , loss avg over log interval:  3.893071622848511\n",
            "Epoch:  6 , Batch:  99 , loss avg over log interval:  3.8889456176757813\n",
            "saving model\n",
            "Epoch:  6 , Batch:  124 , loss avg over log interval:  3.8970647430419922\n",
            "saving model\n",
            "Epoch:  6 , avg total loss:  3.895768461162097\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03083933768795641\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 6/99 Completed\n",
            "Epoch:  7 , Batch:  0 , loss avg over log interval:  3.8891208171844482\n",
            "Epoch:  7 , Batch:  24 , loss avg over log interval:  3.7407072448730467\n",
            "Epoch:  7 , Batch:  49 , loss avg over log interval:  3.899588232040405\n",
            "saving model\n",
            "Epoch:  7 , Batch:  74 , loss avg over log interval:  3.8929997444152833\n",
            "Epoch:  7 , Batch:  99 , loss avg over log interval:  3.8958272457122805\n",
            "saving model\n",
            "Epoch:  7 , Batch:  124 , loss avg over log interval:  3.895734739303589\n",
            "saving model\n",
            "Epoch:  7 , avg total loss:  3.8966735846375764\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030828959405998994\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 7/99 Completed\n",
            "Epoch:  8 , Batch:  0 , loss avg over log interval:  3.8780739307403564\n",
            "Epoch:  8 , Batch:  24 , loss avg over log interval:  3.7385708713531494\n",
            "Epoch:  8 , Batch:  49 , loss avg over log interval:  3.893448715209961\n",
            "saving model\n",
            "Epoch:  8 , Batch:  74 , loss avg over log interval:  3.8921754264831545\n",
            "Epoch:  8 , Batch:  99 , loss avg over log interval:  3.8894003200531007\n",
            "saving model\n",
            "Epoch:  8 , Batch:  124 , loss avg over log interval:  3.898850688934326\n",
            "saving model\n",
            "Epoch:  8 , avg total loss:  3.89410526785132\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.03081334196609238\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 8/99 Completed\n",
            "Epoch:  9 , Batch:  0 , loss avg over log interval:  3.8924081325531006\n",
            "Epoch:  9 , Batch:  24 , loss avg over log interval:  3.74031005859375\n",
            "Epoch:  9 , Batch:  49 , loss avg over log interval:  3.8972435760498048\n",
            "saving model\n",
            "Epoch:  9 , Batch:  74 , loss avg over log interval:  3.8933589363098147\n",
            "Epoch:  9 , Batch:  99 , loss avg over log interval:  3.895781984329224\n",
            "saving model\n",
            "Epoch:  9 , Batch:  124 , loss avg over log interval:  3.8926061534881593\n",
            "saving model\n",
            "Epoch:  9 , avg total loss:  3.894934270479908\n",
            "iter   0\n",
            "accuracy so far =  0.0\n",
            "Avg Validation Loss:  0.030793691652195938\n",
            "Accuracy:  0.02136205952163593\n",
            "Epoch 9/99 Completed\n",
            "Epoch:  10 , Batch:  0 , loss avg over log interval:  3.890251874923706\n",
            "Epoch:  10 , Batch:  24 , loss avg over log interval:  3.7361621284484863\n",
            "Epoch:  10 , Batch:  49 , loss avg over log interval:  3.8900469970703124\n",
            "saving model\n",
            "Epoch:  10 , Batch:  74 , loss avg over log interval:  3.8878743648529053\n",
            "Epoch:  10 , Batch:  99 , loss avg over log interval:  3.890440273284912\n",
            "saving model\n",
            "Epoch:  10 , Batch:  124 , loss avg over log interval:  3.894896774291992\n",
            "saving model\n",
            "Epoch:  10 , avg total loss:  3.8919667756720764\n",
            "iter   0\n",
            "accuracy so far =  0.0703125\n",
            "Avg Validation Loss:  0.03076906754453839\n",
            "Accuracy:  0.03231696184042359\n",
            "Epoch 10/99 Completed\n",
            "Epoch:  11 , Batch:  0 , loss avg over log interval:  3.8985774517059326\n",
            "Epoch:  11 , Batch:  24 , loss avg over log interval:  3.733230094909668\n",
            "Epoch:  11 , Batch:  49 , loss avg over log interval:  3.889878149032593\n",
            "saving model\n",
            "Epoch:  11 , Batch:  74 , loss avg over log interval:  3.8875068187713624\n",
            "Epoch:  11 , Batch:  99 , loss avg over log interval:  3.8795909214019777\n",
            "saving model\n",
            "Epoch:  11 , Batch:  124 , loss avg over log interval:  3.88046856880188\n",
            "saving model\n",
            "Epoch:  11 , avg total loss:  3.885858031168376\n",
            "iter   0\n",
            "accuracy so far =  0.4375\n",
            "Avg Validation Loss:  0.03074724499666062\n",
            "Accuracy:  0.05568742012050393\n",
            "Epoch 11/99 Completed\n",
            "Epoch:  12 , Batch:  0 , loss avg over log interval:  3.8762669563293457\n",
            "Epoch:  12 , Batch:  24 , loss avg over log interval:  3.7291894245147703\n",
            "Epoch:  12 , Batch:  49 , loss avg over log interval:  3.8798507499694823\n",
            "saving model\n",
            "Epoch:  12 , Batch:  74 , loss avg over log interval:  3.878203020095825\n",
            "Epoch:  12 , Batch:  99 , loss avg over log interval:  3.881896514892578\n",
            "saving model\n",
            "Epoch:  12 , Batch:  124 , loss avg over log interval:  3.8758604907989502\n",
            "saving model\n",
            "Epoch:  12 , avg total loss:  3.8807347392382687\n",
            "iter   0\n",
            "accuracy so far =  0.7890625\n",
            "Avg Validation Loss:  0.030723866046030026\n",
            "Accuracy:  0.08234434909622056\n",
            "Epoch 12/99 Completed\n",
            "Epoch:  13 , Batch:  0 , loss avg over log interval:  3.8759195804595947\n",
            "Epoch:  13 , Batch:  24 , loss avg over log interval:  3.719972915649414\n",
            "Epoch:  13 , Batch:  49 , loss avg over log interval:  3.88291690826416\n",
            "saving model\n",
            "Epoch:  13 , Batch:  74 , loss avg over log interval:  3.879894847869873\n",
            "Epoch:  13 , Batch:  99 , loss avg over log interval:  3.875617055892944\n",
            "saving model\n",
            "Epoch:  13 , Batch:  124 , loss avg over log interval:  3.8802913284301757\n",
            "saving model\n",
            "Epoch:  13 , avg total loss:  3.878595740827796\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030698907142445536\n",
            "Accuracy:  0.08909987219280628\n",
            "Epoch 13/99 Completed\n",
            "Epoch:  14 , Batch:  0 , loss avg over log interval:  3.883164882659912\n",
            "Epoch:  14 , Batch:  24 , loss avg over log interval:  3.717197217941284\n",
            "Epoch:  14 , Batch:  49 , loss avg over log interval:  3.881415157318115\n",
            "saving model\n",
            "Epoch:  14 , Batch:  74 , loss avg over log interval:  3.8742488956451417\n",
            "Epoch:  14 , Batch:  99 , loss avg over log interval:  3.871498022079468\n",
            "saving model\n",
            "Epoch:  14 , Batch:  124 , loss avg over log interval:  3.8790388202667234\n",
            "saving model\n",
            "Epoch:  14 , avg total loss:  3.87563886217875\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030670754770651905\n",
            "Accuracy:  0.09202117947781632\n",
            "Epoch 14/99 Completed\n",
            "Epoch:  15 , Batch:  0 , loss avg over log interval:  3.8669185638427734\n",
            "Epoch:  15 , Batch:  24 , loss avg over log interval:  3.720786714553833\n",
            "Epoch:  15 , Batch:  49 , loss avg over log interval:  3.8756790733337403\n",
            "saving model\n",
            "Epoch:  15 , Batch:  74 , loss avg over log interval:  3.8681865978240966\n",
            "Epoch:  15 , Batch:  99 , loss avg over log interval:  3.8665345096588135\n",
            "saving model\n",
            "Epoch:  15 , Batch:  124 , loss avg over log interval:  3.870828514099121\n",
            "saving model\n",
            "Epoch:  15 , avg total loss:  3.872109238415548\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.0306385630387687\n",
            "Accuracy:  0.09256892459375571\n",
            "Epoch 15/99 Completed\n",
            "Epoch:  16 , Batch:  0 , loss avg over log interval:  3.8661179542541504\n",
            "Epoch:  16 , Batch:  24 , loss avg over log interval:  3.7157836723327637\n",
            "Epoch:  16 , Batch:  49 , loss avg over log interval:  3.8695575904846193\n",
            "saving model\n",
            "Epoch:  16 , Batch:  74 , loss avg over log interval:  3.867466678619385\n",
            "Epoch:  16 , Batch:  99 , loss avg over log interval:  3.8685753250122072\n",
            "saving model\n",
            "Epoch:  16 , Batch:  124 , loss avg over log interval:  3.8700973701477053\n",
            "saving model\n",
            "Epoch:  16 , avg total loss:  3.8697162050090426\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.03062562993000693\n",
            "Accuracy:  0.09329925141500822\n",
            "Epoch 16/99 Completed\n",
            "Epoch:  17 , Batch:  0 , loss avg over log interval:  3.892667055130005\n",
            "Epoch:  17 , Batch:  24 , loss avg over log interval:  3.706538209915161\n",
            "Epoch:  17 , Batch:  49 , loss avg over log interval:  3.867976636886597\n",
            "saving model\n",
            "Epoch:  17 , Batch:  74 , loss avg over log interval:  3.8685114669799803\n",
            "Epoch:  17 , Batch:  99 , loss avg over log interval:  3.8634876155853273\n",
            "saving model\n",
            "Epoch:  17 , Batch:  124 , loss avg over log interval:  3.8736328887939453\n",
            "saving model\n",
            "Epoch:  17 , avg total loss:  3.8674844585052908\n",
            "iter   0\n",
            "accuracy so far =  0.90625\n",
            "Avg Validation Loss:  0.030610429559372977\n",
            "Accuracy:  0.09329925141500822\n",
            "Epoch 17/99 Completed\n",
            "Epoch:  18 , Batch:  0 , loss avg over log interval:  3.8545613288879395\n",
            "Epoch:  18 , Batch:  24 , loss avg over log interval:  3.7103826713562014\n",
            "Epoch:  18 , Batch:  49 , loss avg over log interval:  3.8648317432403565\n",
            "saving model\n",
            "Epoch:  18 , Batch:  74 , loss avg over log interval:  3.8683555507659912\n",
            "Epoch:  18 , Batch:  99 , loss avg over log interval:  3.865198001861572\n",
            "saving model\n",
            "Epoch:  18 , Batch:  124 , loss avg over log interval:  3.862558603286743\n",
            "saving model\n",
            "Epoch:  18 , avg total loss:  3.8662018106408316\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030598273781370196\n",
            "Accuracy:  0.0931166697096951\n",
            "Epoch 18/99 Completed\n",
            "Epoch:  19 , Batch:  0 , loss avg over log interval:  3.8602306842803955\n",
            "Epoch:  19 , Batch:  24 , loss avg over log interval:  3.710045118331909\n",
            "Epoch:  19 , Batch:  49 , loss avg over log interval:  3.8653432083129884\n",
            "saving model\n",
            "Epoch:  19 , Batch:  74 , loss avg over log interval:  3.86399224281311\n",
            "Epoch:  19 , Batch:  99 , loss avg over log interval:  3.8634203243255616\n",
            "saving model\n",
            "Epoch:  19 , Batch:  124 , loss avg over log interval:  3.863007593154907\n",
            "saving model\n",
            "Epoch:  19 , avg total loss:  3.8652269448319525\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030586403609410416\n",
            "Accuracy:  0.09348183312032135\n",
            "Epoch 19/99 Completed\n",
            "Epoch:  20 , Batch:  0 , loss avg over log interval:  3.8622305393218994\n",
            "Epoch:  20 , Batch:  24 , loss avg over log interval:  3.704039602279663\n",
            "Epoch:  20 , Batch:  49 , loss avg over log interval:  3.860063199996948\n",
            "saving model\n",
            "Epoch:  20 , Batch:  74 , loss avg over log interval:  3.8567872524261473\n",
            "Epoch:  20 , Batch:  99 , loss avg over log interval:  3.8603027725219725\n",
            "saving model\n",
            "Epoch:  20 , Batch:  124 , loss avg over log interval:  3.86739821434021\n",
            "saving model\n",
            "Epoch:  20 , avg total loss:  3.860950035591648\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030567484265895617\n",
            "Accuracy:  0.09475990505751324\n",
            "Epoch 20/99 Completed\n",
            "Epoch:  21 , Batch:  0 , loss avg over log interval:  3.865842580795288\n",
            "Epoch:  21 , Batch:  24 , loss avg over log interval:  3.7039386463165282\n",
            "Epoch:  21 , Batch:  49 , loss avg over log interval:  3.8558044910430906\n",
            "saving model\n",
            "Epoch:  21 , Batch:  74 , loss avg over log interval:  3.8647477626800537\n",
            "Epoch:  21 , Batch:  99 , loss avg over log interval:  3.8527056694030763\n",
            "saving model\n",
            "Epoch:  21 , Batch:  124 , loss avg over log interval:  3.865658359527588\n",
            "saving model\n",
            "Epoch:  21 , avg total loss:  3.859567782650255\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030551284295876616\n",
            "Accuracy:  0.1024283366806646\n",
            "Epoch 21/99 Completed\n",
            "Epoch:  22 , Batch:  0 , loss avg over log interval:  3.874671697616577\n",
            "Epoch:  22 , Batch:  24 , loss avg over log interval:  3.7018282222747803\n",
            "Epoch:  22 , Batch:  49 , loss avg over log interval:  3.863027458190918\n",
            "saving model\n",
            "Epoch:  22 , Batch:  74 , loss avg over log interval:  3.86163423538208\n",
            "Epoch:  22 , Batch:  99 , loss avg over log interval:  3.8477875900268557\n",
            "saving model\n",
            "Epoch:  22 , Batch:  124 , loss avg over log interval:  3.8589835929870606\n",
            "saving model\n",
            "Epoch:  22 , avg total loss:  3.859403375076921\n",
            "iter   0\n",
            "accuracy so far =  0.9140625\n",
            "Avg Validation Loss:  0.030532184125124723\n",
            "Accuracy:  0.11484389264195728\n",
            "Epoch 22/99 Completed\n",
            "Epoch:  23 , Batch:  0 , loss avg over log interval:  3.860783338546753\n",
            "Epoch:  23 , Batch:  24 , loss avg over log interval:  3.6981325340270996\n",
            "Epoch:  23 , Batch:  49 , loss avg over log interval:  3.850195779800415\n",
            "saving model\n",
            "Epoch:  23 , Batch:  74 , loss avg over log interval:  3.852111692428589\n",
            "Epoch:  23 , Batch:  99 , loss avg over log interval:  3.8530770683288575\n",
            "saving model\n",
            "Epoch:  23 , Batch:  124 , loss avg over log interval:  3.855974349975586\n",
            "saving model\n",
            "Epoch:  23 , avg total loss:  3.853689036957205\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.030493012522832742\n",
            "Accuracy:  0.13182399123607816\n",
            "Epoch 23/99 Completed\n",
            "Epoch:  24 , Batch:  0 , loss avg over log interval:  3.8556551933288574\n",
            "Epoch:  24 , Batch:  24 , loss avg over log interval:  3.7044108963012694\n",
            "Epoch:  24 , Batch:  49 , loss avg over log interval:  3.854782152175903\n",
            "saving model\n",
            "Epoch:  24 , Batch:  74 , loss avg over log interval:  3.8613535881042482\n",
            "Epoch:  24 , Batch:  99 , loss avg over log interval:  3.8449140071868895\n",
            "saving model\n",
            "Epoch:  24 , Batch:  124 , loss avg over log interval:  3.846728467941284\n",
            "saving model\n",
            "Epoch:  24 , avg total loss:  3.8535745846082086\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.03046775073144957\n",
            "Accuracy:  0.140222749680482\n",
            "Epoch 24/99 Completed\n",
            "Epoch:  25 , Batch:  0 , loss avg over log interval:  3.8336968421936035\n",
            "Epoch:  25 , Batch:  24 , loss avg over log interval:  3.696816253662109\n",
            "Epoch:  25 , Batch:  49 , loss avg over log interval:  3.8499246311187743\n",
            "saving model\n",
            "Epoch:  25 , Batch:  74 , loss avg over log interval:  3.84529559135437\n",
            "Epoch:  25 , Batch:  99 , loss avg over log interval:  3.8507780265808105\n",
            "saving model\n",
            "Epoch:  25 , Batch:  124 , loss avg over log interval:  3.8415605354309084\n",
            "saving model\n",
            "Epoch:  25 , avg total loss:  3.8481979402777267\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030440525001301608\n",
            "Accuracy:  0.1440569654920577\n",
            "Epoch 25/99 Completed\n",
            "Epoch:  26 , Batch:  0 , loss avg over log interval:  3.898146152496338\n",
            "Epoch:  26 , Batch:  24 , loss avg over log interval:  3.688056230545044\n",
            "Epoch:  26 , Batch:  49 , loss avg over log interval:  3.846546936035156\n",
            "saving model\n",
            "Epoch:  26 , Batch:  74 , loss avg over log interval:  3.8463042831420897\n",
            "Epoch:  26 , Batch:  99 , loss avg over log interval:  3.836005754470825\n",
            "saving model\n",
            "Epoch:  26 , Batch:  124 , loss avg over log interval:  3.8436234474182127\n",
            "saving model\n",
            "Epoch:  26 , avg total loss:  3.843546317048269\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030410589996819865\n",
            "Accuracy:  0.1480737630089465\n",
            "Epoch 26/99 Completed\n",
            "Epoch:  27 , Batch:  0 , loss avg over log interval:  3.8540892601013184\n",
            "Epoch:  27 , Batch:  24 , loss avg over log interval:  3.6863654899597167\n",
            "Epoch:  27 , Batch:  49 , loss avg over log interval:  3.840614604949951\n",
            "saving model\n",
            "Epoch:  27 , Batch:  74 , loss avg over log interval:  3.8451798152923584\n",
            "Epoch:  27 , Batch:  99 , loss avg over log interval:  3.839995098114014\n",
            "saving model\n",
            "Epoch:  27 , Batch:  124 , loss avg over log interval:  3.8435109138488768\n",
            "saving model\n",
            "Epoch:  27 , avg total loss:  3.842094120913989\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.030402430178628516\n",
            "Accuracy:  0.14770859959832025\n",
            "Epoch 27/99 Completed\n",
            "Epoch:  28 , Batch:  0 , loss avg over log interval:  3.8384974002838135\n",
            "Epoch:  28 , Batch:  24 , loss avg over log interval:  3.679737062454224\n",
            "Epoch:  28 , Batch:  49 , loss avg over log interval:  3.8413397026062013\n",
            "saving model\n",
            "Epoch:  28 , Batch:  74 , loss avg over log interval:  3.8441061115264894\n",
            "Epoch:  28 , Batch:  99 , loss avg over log interval:  3.836131467819214\n",
            "saving model\n",
            "Epoch:  28 , Batch:  124 , loss avg over log interval:  3.8464269638061523\n",
            "saving model\n",
            "Epoch:  28 , avg total loss:  3.841406469475733\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "Avg Validation Loss:  0.03039225239986178\n",
            "Accuracy:  0.1486215081248859\n",
            "Epoch 28/99 Completed\n",
            "Epoch:  29 , Batch:  0 , loss avg over log interval:  3.8453402519226074\n",
            "Epoch:  29 , Batch:  24 , loss avg over log interval:  3.6848777866363527\n",
            "Epoch:  29 , Batch:  49 , loss avg over log interval:  3.8353560543060303\n",
            "saving model\n",
            "Epoch:  29 , Batch:  74 , loss avg over log interval:  3.843021898269653\n",
            "Epoch:  29 , Batch:  99 , loss avg over log interval:  3.8372482299804687\n",
            "saving model\n",
            "Epoch:  29 , Batch:  124 , loss avg over log interval:  3.838442678451538\n",
            "saving model\n",
            "Epoch:  29 , avg total loss:  3.838867830903563\n",
            "iter   0\n",
            "accuracy so far =  0.8984375\n",
            "Avg Validation Loss:  0.030362138309377767\n",
            "Accuracy:  0.1513602337045828\n",
            "Epoch 29/99 Completed\n",
            "Epoch:  30 , Batch:  0 , loss avg over log interval:  3.8659582138061523\n",
            "Epoch:  30 , Batch:  24 , loss avg over log interval:  3.680259370803833\n",
            "Epoch:  30 , Batch:  49 , loss avg over log interval:  3.8353388690948487\n",
            "saving model\n",
            "Epoch:  30 , Batch:  74 , loss avg over log interval:  3.838048553466797\n",
            "Epoch:  30 , Batch:  99 , loss avg over log interval:  3.8306284523010254\n",
            "saving model\n",
            "Epoch:  30 , Batch:  124 , loss avg over log interval:  3.8377813053131105\n",
            "saving model\n",
            "Epoch:  30 , avg total loss:  3.836048622653909\n",
            "iter   0\n",
            "accuracy so far =  0.875\n",
            "Avg Validation Loss:  0.03035520532171679\n",
            "Accuracy:  0.15172539711520905\n",
            "Epoch 30/99 Completed\n",
            "Epoch:  31 , Batch:  0 , loss avg over log interval:  3.828359603881836\n",
            "Epoch:  31 , Batch:  24 , loss avg over log interval:  3.6876440620422364\n",
            "Epoch:  31 , Batch:  49 , loss avg over log interval:  3.8380620098114013\n",
            "saving model\n",
            "Epoch:  31 , Batch:  74 , loss avg over log interval:  3.8357451820373534\n",
            "Epoch:  31 , Batch:  99 , loss avg over log interval:  3.831401424407959\n",
            "saving model\n",
            "Epoch:  31 , Batch:  124 , loss avg over log interval:  3.8391668128967287\n",
            "saving model\n",
            "Epoch:  31 , avg total loss:  3.8383664888878393\n",
            "iter   0\n",
            "accuracy so far =  0.8671875\n",
            "Avg Validation Loss:  0.030345364080111823\n",
            "Accuracy:  0.15647252145335036\n",
            "Epoch 31/99 Completed\n",
            "Epoch:  32 , Batch:  0 , loss avg over log interval:  3.835176944732666\n",
            "Epoch:  32 , Batch:  24 , loss avg over log interval:  3.6828221893310547\n",
            "Epoch:  32 , Batch:  49 , loss avg over log interval:  3.842431049346924\n",
            "saving model\n",
            "Epoch:  32 , Batch:  74 , loss avg over log interval:  3.8312861156463622\n",
            "Epoch:  32 , Batch:  99 , loss avg over log interval:  3.8290432834625245\n",
            "saving model\n",
            "Epoch:  32 , Batch:  124 , loss avg over log interval:  3.841497735977173\n",
            "saving model\n",
            "Epoch:  32 , avg total loss:  3.8370508527102536\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030340149125326763\n",
            "Accuracy:  0.16176739090743109\n",
            "Epoch 32/99 Completed\n",
            "Epoch:  33 , Batch:  0 , loss avg over log interval:  3.8404757976531982\n",
            "Epoch:  33 , Batch:  24 , loss avg over log interval:  3.679731912612915\n",
            "Epoch:  33 , Batch:  49 , loss avg over log interval:  3.838310956954956\n",
            "saving model\n",
            "Epoch:  33 , Batch:  74 , loss avg over log interval:  3.834595966339111\n",
            "Epoch:  33 , Batch:  99 , loss avg over log interval:  3.829091033935547\n",
            "saving model\n",
            "Epoch:  33 , Batch:  124 , loss avg over log interval:  3.8393278026580813\n",
            "saving model\n",
            "Epoch:  33 , avg total loss:  3.8346811532974243\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.03033022848341355\n",
            "Accuracy:  0.165966770129633\n",
            "Epoch 33/99 Completed\n",
            "Epoch:  34 , Batch:  0 , loss avg over log interval:  3.8575785160064697\n",
            "Epoch:  34 , Batch:  24 , loss avg over log interval:  3.673376340866089\n",
            "Epoch:  34 , Batch:  49 , loss avg over log interval:  3.8274487686157226\n",
            "saving model\n",
            "Epoch:  34 , Batch:  74 , loss avg over log interval:  3.825390157699585\n",
            "Epoch:  34 , Batch:  99 , loss avg over log interval:  3.823269805908203\n",
            "saving model\n",
            "Epoch:  34 , Batch:  124 , loss avg over log interval:  3.8385088443756104\n",
            "saving model\n",
            "Epoch:  34 , avg total loss:  3.8302568850451952\n",
            "iter   0\n",
            "accuracy so far =  0.875\n",
            "Avg Validation Loss:  0.03032267178543645\n",
            "Accuracy:  0.1699835676465218\n",
            "Epoch 34/99 Completed\n",
            "Epoch:  35 , Batch:  0 , loss avg over log interval:  3.815263271331787\n",
            "Epoch:  35 , Batch:  24 , loss avg over log interval:  3.671091842651367\n",
            "Epoch:  35 , Batch:  49 , loss avg over log interval:  3.8281429958343507\n",
            "saving model\n",
            "Epoch:  35 , Batch:  74 , loss avg over log interval:  3.8335103797912597\n",
            "Epoch:  35 , Batch:  99 , loss avg over log interval:  3.8244942569732667\n",
            "saving model\n",
            "Epoch:  35 , Batch:  124 , loss avg over log interval:  3.829735879898071\n",
            "saving model\n",
            "Epoch:  35 , avg total loss:  3.828523790999635\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.030307631260159895\n",
            "Accuracy:  0.16943582253058243\n",
            "Epoch 35/99 Completed\n",
            "Epoch:  36 , Batch:  0 , loss avg over log interval:  3.8056201934814453\n",
            "Epoch:  36 , Batch:  24 , loss avg over log interval:  3.6678091621398927\n",
            "Epoch:  36 , Batch:  49 , loss avg over log interval:  3.8212135791778565\n",
            "saving model\n",
            "Epoch:  36 , Batch:  74 , loss avg over log interval:  3.834668617248535\n",
            "Epoch:  36 , Batch:  99 , loss avg over log interval:  3.8239270782470705\n",
            "saving model\n",
            "Epoch:  36 , Batch:  124 , loss avg over log interval:  3.8303590488433836\n",
            "saving model\n",
            "Epoch:  36 , avg total loss:  3.825991544004989\n",
            "iter   0\n",
            "accuracy so far =  0.8515625\n",
            "Avg Validation Loss:  0.030294523592606412\n",
            "Accuracy:  0.16870549570932994\n",
            "Epoch 36/99 Completed\n",
            "Epoch:  37 , Batch:  0 , loss avg over log interval:  3.8051116466522217\n",
            "Epoch:  37 , Batch:  24 , loss avg over log interval:  3.6696235084533693\n",
            "Epoch:  37 , Batch:  49 , loss avg over log interval:  3.8300929164886472\n",
            "saving model\n",
            "Epoch:  37 , Batch:  74 , loss avg over log interval:  3.8266465568542483\n",
            "Epoch:  37 , Batch:  99 , loss avg over log interval:  3.8179730987548828\n",
            "saving model\n",
            "Epoch:  37 , Batch:  124 , loss avg over log interval:  3.825390033721924\n",
            "saving model\n",
            "Epoch:  37 , avg total loss:  3.826297291337627\n",
            "iter   0\n",
            "accuracy so far =  0.828125\n",
            "Avg Validation Loss:  0.030295337924605547\n",
            "Accuracy:  0.17290487493153187\n",
            "Epoch 37/99 Completed\n",
            "Epoch:  38 , Batch:  0 , loss avg over log interval:  3.850527286529541\n",
            "Epoch:  38 , Batch:  24 , loss avg over log interval:  3.665460214614868\n",
            "Epoch:  38 , Batch:  49 , loss avg over log interval:  3.816428289413452\n",
            "saving model\n",
            "Epoch:  38 , Batch:  74 , loss avg over log interval:  3.8290438556671145\n",
            "Epoch:  38 , Batch:  99 , loss avg over log interval:  3.823926315307617\n",
            "saving model\n",
            "Epoch:  38 , Batch:  124 , loss avg over log interval:  3.8198999118804933\n",
            "saving model\n",
            "Epoch:  38 , avg total loss:  3.823033094406128\n",
            "iter   0\n",
            "accuracy so far =  0.859375\n",
            "Avg Validation Loss:  0.030271553179197816\n",
            "Accuracy:  0.17290487493153187\n",
            "Epoch 38/99 Completed\n",
            "Epoch:  39 , Batch:  0 , loss avg over log interval:  3.812802791595459\n",
            "Epoch:  39 , Batch:  24 , loss avg over log interval:  3.6622192001342775\n",
            "Epoch:  39 , Batch:  49 , loss avg over log interval:  3.8155573272705077\n",
            "saving model\n",
            "Epoch:  39 , Batch:  74 , loss avg over log interval:  3.813474235534668\n",
            "Epoch:  39 , Batch:  99 , loss avg over log interval:  3.8214159488677977\n",
            "saving model\n",
            "Epoch:  39 , Batch:  124 , loss avg over log interval:  3.8230933856964113\n",
            "saving model\n",
            "Epoch:  39 , avg total loss:  3.8191042795573193\n",
            "iter   0\n",
            "accuracy so far =  0.8359375\n",
            "Avg Validation Loss:  0.03026211329222117\n",
            "Accuracy:  0.17400036516341064\n",
            "Epoch 39/99 Completed\n",
            "Epoch:  40 , Batch:  0 , loss avg over log interval:  3.7923290729522705\n",
            "Epoch:  40 , Batch:  24 , loss avg over log interval:  3.6617180919647216\n",
            "Epoch:  40 , Batch:  49 , loss avg over log interval:  3.8214082431793215\n",
            "saving model\n",
            "Epoch:  40 , Batch:  74 , loss avg over log interval:  3.811834020614624\n",
            "Epoch:  40 , Batch:  99 , loss avg over log interval:  3.81620436668396\n",
            "saving model\n",
            "Epoch:  40 , Batch:  124 , loss avg over log interval:  3.8152706623077393\n",
            "saving model\n",
            "Epoch:  40 , avg total loss:  3.8161666017689115\n",
            "iter   0\n",
            "accuracy so far =  0.8203125\n",
            "Avg Validation Loss:  0.030256570549979357\n",
            "Accuracy:  0.18860690158846083\n",
            "Epoch 40/99 Completed\n",
            "Epoch:  41 , Batch:  0 , loss avg over log interval:  3.818654775619507\n",
            "Epoch:  41 , Batch:  24 , loss avg over log interval:  3.665177345275879\n",
            "Epoch:  41 , Batch:  49 , loss avg over log interval:  3.813883876800537\n",
            "saving model\n",
            "Epoch:  41 , Batch:  74 , loss avg over log interval:  3.813223705291748\n",
            "Epoch:  41 , Batch:  99 , loss avg over log interval:  3.7996556854248045\n",
            "saving model\n",
            "Epoch:  41 , Batch:  124 , loss avg over log interval:  3.8166878414154053\n",
            "saving model\n",
            "Epoch:  41 , avg total loss:  3.811220066188133\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.03023197129844901\n",
            "Accuracy:  0.1957275880956728\n",
            "Epoch 41/99 Completed\n",
            "Epoch:  42 , Batch:  0 , loss avg over log interval:  3.8308236598968506\n",
            "Epoch:  42 , Batch:  24 , loss avg over log interval:  3.6584120750427247\n",
            "Epoch:  42 , Batch:  49 , loss avg over log interval:  3.8166721630096436\n",
            "saving model\n",
            "Epoch:  42 , Batch:  74 , loss avg over log interval:  3.801827688217163\n",
            "Epoch:  42 , Batch:  99 , loss avg over log interval:  3.8030046081542968\n",
            "saving model\n",
            "Epoch:  42 , Batch:  124 , loss avg over log interval:  3.807929391860962\n",
            "saving model\n",
            "Epoch:  42 , avg total loss:  3.8080456779427725\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.030184850045009665\n",
            "Accuracy:  0.2041263465400767\n",
            "Epoch 42/99 Completed\n",
            "Epoch:  43 , Batch:  0 , loss avg over log interval:  3.749556303024292\n",
            "Epoch:  43 , Batch:  24 , loss avg over log interval:  3.6513257312774656\n",
            "Epoch:  43 , Batch:  49 , loss avg over log interval:  3.8016048526763915\n",
            "saving model\n",
            "Epoch:  43 , Batch:  74 , loss avg over log interval:  3.8083852195739745\n",
            "Epoch:  43 , Batch:  99 , loss avg over log interval:  3.7995298671722413\n",
            "saving model\n",
            "Epoch:  43 , Batch:  124 , loss avg over log interval:  3.800718584060669\n",
            "saving model\n",
            "Epoch:  43 , avg total loss:  3.80316746724795\n",
            "iter   0\n",
            "accuracy so far =  0.765625\n",
            "Avg Validation Loss:  0.030147166806719524\n",
            "Accuracy:  0.21617673909074311\n",
            "Epoch 43/99 Completed\n",
            "Epoch:  44 , Batch:  0 , loss avg over log interval:  3.8056628704071045\n",
            "Epoch:  44 , Batch:  24 , loss avg over log interval:  3.6440753078460695\n",
            "Epoch:  44 , Batch:  49 , loss avg over log interval:  3.800383138656616\n",
            "saving model\n",
            "Epoch:  44 , Batch:  74 , loss avg over log interval:  3.7951207542419434\n",
            "Epoch:  44 , Batch:  99 , loss avg over log interval:  3.8017513751983643\n",
            "saving model\n",
            "Epoch:  44 , Batch:  124 , loss avg over log interval:  3.7918595981597902\n",
            "saving model\n",
            "Epoch:  44 , avg total loss:  3.7968586683273315\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.03011497590192287\n",
            "Accuracy:  0.21617673909074311\n",
            "Epoch 44/99 Completed\n",
            "Epoch:  45 , Batch:  0 , loss avg over log interval:  3.783402919769287\n",
            "Epoch:  45 , Batch:  24 , loss avg over log interval:  3.6390627098083494\n",
            "Epoch:  45 , Batch:  49 , loss avg over log interval:  3.7904148960113524\n",
            "saving model\n",
            "Epoch:  45 , Batch:  74 , loss avg over log interval:  3.8008467102050782\n",
            "Epoch:  45 , Batch:  99 , loss avg over log interval:  3.7928754806518556\n",
            "saving model\n",
            "Epoch:  45 , Batch:  124 , loss avg over log interval:  3.7942230987548826\n",
            "saving model\n",
            "Epoch:  45 , avg total loss:  3.794451277549953\n",
            "iter   0\n",
            "accuracy so far =  0.765625\n",
            "Avg Validation Loss:  0.030075859235589773\n",
            "Accuracy:  0.21982837319700566\n",
            "Epoch 45/99 Completed\n",
            "Epoch:  46 , Batch:  0 , loss avg over log interval:  3.725555658340454\n",
            "Epoch:  46 , Batch:  24 , loss avg over log interval:  3.6396086692810057\n",
            "Epoch:  46 , Batch:  49 , loss avg over log interval:  3.788105297088623\n",
            "saving model\n",
            "Epoch:  46 , Batch:  74 , loss avg over log interval:  3.799027280807495\n",
            "Epoch:  46 , Batch:  99 , loss avg over log interval:  3.7848322105407717\n",
            "saving model\n",
            "Epoch:  46 , Batch:  124 , loss avg over log interval:  3.796048812866211\n",
            "saving model\n",
            "Epoch:  46 , avg total loss:  3.7923268210398007\n",
            "iter   0\n",
            "accuracy so far =  0.8125\n",
            "Avg Validation Loss:  0.03003584948991236\n",
            "Accuracy:  0.23443490962205588\n",
            "Epoch 46/99 Completed\n",
            "Epoch:  47 , Batch:  0 , loss avg over log interval:  3.813992500305176\n",
            "Epoch:  47 , Batch:  24 , loss avg over log interval:  3.6448364543914793\n",
            "Epoch:  47 , Batch:  49 , loss avg over log interval:  3.791837701797485\n",
            "saving model\n",
            "Epoch:  47 , Batch:  74 , loss avg over log interval:  3.79362193107605\n",
            "Epoch:  47 , Batch:  99 , loss avg over log interval:  3.7910016632080077\n",
            "saving model\n",
            "Epoch:  47 , Batch:  124 , loss avg over log interval:  3.780507402420044\n",
            "saving model\n",
            "Epoch:  47 , avg total loss:  3.7907085304390895\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.03001623234653943\n",
            "Accuracy:  0.2426510863611466\n",
            "Epoch 47/99 Completed\n",
            "Epoch:  48 , Batch:  0 , loss avg over log interval:  3.7884979248046875\n",
            "Epoch:  48 , Batch:  24 , loss avg over log interval:  3.6252852630615235\n",
            "Epoch:  48 , Batch:  49 , loss avg over log interval:  3.790121603012085\n",
            "saving model\n",
            "Epoch:  48 , Batch:  74 , loss avg over log interval:  3.791868896484375\n",
            "Epoch:  48 , Batch:  99 , loss avg over log interval:  3.774949378967285\n",
            "saving model\n",
            "Epoch:  48 , Batch:  124 , loss avg over log interval:  3.777653150558472\n",
            "saving model\n",
            "Epoch:  48 , avg total loss:  3.7817771500104094\n",
            "iter   0\n",
            "accuracy so far =  0.7890625\n",
            "Avg Validation Loss:  0.029981778837673764\n",
            "Accuracy:  0.2477633741099142\n",
            "Epoch 48/99 Completed\n",
            "Epoch:  49 , Batch:  0 , loss avg over log interval:  3.7529561519622803\n",
            "Epoch:  49 , Batch:  24 , loss avg over log interval:  3.6247323989868163\n",
            "Epoch:  49 , Batch:  49 , loss avg over log interval:  3.780726099014282\n",
            "saving model\n",
            "Epoch:  49 , Batch:  74 , loss avg over log interval:  3.792705478668213\n",
            "Epoch:  49 , Batch:  99 , loss avg over log interval:  3.7765878009796143\n",
            "saving model\n",
            "Epoch:  49 , Batch:  124 , loss avg over log interval:  3.786172456741333\n",
            "saving model\n",
            "Epoch:  49 , avg total loss:  3.7825606293874245\n",
            "iter   0\n",
            "accuracy so far =  0.734375\n",
            "Avg Validation Loss:  0.029946590788895052\n",
            "Accuracy:  0.25013693627898487\n",
            "Epoch 49/99 Completed\n",
            "Epoch:  50 , Batch:  0 , loss avg over log interval:  3.8204171657562256\n",
            "Epoch:  50 , Batch:  24 , loss avg over log interval:  3.6262504482269287\n",
            "Epoch:  50 , Batch:  49 , loss avg over log interval:  3.794935998916626\n",
            "saving model\n",
            "Epoch:  50 , Batch:  74 , loss avg over log interval:  3.787344617843628\n",
            "Epoch:  50 , Batch:  99 , loss avg over log interval:  3.7821664905548094\n",
            "saving model\n",
            "Epoch:  50 , Batch:  124 , loss avg over log interval:  3.7839924621582033\n",
            "saving model\n",
            "Epoch:  50 , avg total loss:  3.78562164469941\n",
            "iter   0\n",
            "accuracy so far =  0.7109375\n",
            "Avg Validation Loss:  0.029922193433543246\n",
            "Accuracy:  0.24849370093116668\n",
            "Epoch 50/99 Completed\n",
            "Epoch:  51 , Batch:  0 , loss avg over log interval:  3.7574405670166016\n",
            "Epoch:  51 , Batch:  24 , loss avg over log interval:  3.6202665996551513\n",
            "Epoch:  51 , Batch:  49 , loss avg over log interval:  3.7773937511444093\n",
            "saving model\n",
            "Epoch:  51 , Batch:  74 , loss avg over log interval:  3.7788447093963624\n",
            "Epoch:  51 , Batch:  99 , loss avg over log interval:  3.770654878616333\n",
            "saving model\n",
            "Epoch:  51 , Batch:  124 , loss avg over log interval:  3.776009826660156\n",
            "saving model\n",
            "Epoch:  51 , avg total loss:  3.773730353133319\n",
            "iter   0\n",
            "accuracy so far =  0.78125\n",
            "Avg Validation Loss:  0.0298889669728623\n",
            "Accuracy:  0.25397115209056054\n",
            "Epoch 51/99 Completed\n",
            "Epoch:  52 , Batch:  0 , loss avg over log interval:  3.829092025756836\n",
            "Epoch:  52 , Batch:  24 , loss avg over log interval:  3.6312403869628906\n",
            "Epoch:  52 , Batch:  49 , loss avg over log interval:  3.7855107498168947\n",
            "saving model\n",
            "Epoch:  52 , Batch:  74 , loss avg over log interval:  3.7687703132629395\n",
            "Epoch:  52 , Batch:  99 , loss avg over log interval:  3.772880058288574\n",
            "saving model\n",
            "Epoch:  52 , Batch:  124 , loss avg over log interval:  3.7688176345825197\n",
            "saving model\n",
            "Epoch:  52 , avg total loss:  3.775170625072636\n",
            "iter   0\n",
            "accuracy so far =  0.7734375\n",
            "Avg Validation Loss:  0.029869908374091973\n",
            "Accuracy:  0.2557969691436918\n",
            "Epoch 52/99 Completed\n",
            "Epoch:  53 , Batch:  0 , loss avg over log interval:  3.8058583736419678\n",
            "Epoch:  53 , Batch:  24 , loss avg over log interval:  3.6206329250335694\n",
            "Epoch:  53 , Batch:  49 , loss avg over log interval:  3.78144136428833\n",
            "saving model\n",
            "Epoch:  53 , Batch:  74 , loss avg over log interval:  3.7762816524505616\n",
            "Epoch:  53 , Batch:  99 , loss avg over log interval:  3.7698923110961915\n",
            "saving model\n",
            "Epoch:  53 , Batch:  124 , loss avg over log interval:  3.774124641418457\n",
            "saving model\n",
            "Epoch:  53 , avg total loss:  3.7727994592222447\n",
            "iter   0\n",
            "accuracy so far =  0.71875\n",
            "Avg Validation Loss:  0.02986185080991602\n",
            "Accuracy:  0.2570750410808837\n",
            "Epoch 53/99 Completed\n",
            "Epoch:  54 , Batch:  0 , loss avg over log interval:  3.782994508743286\n",
            "Epoch:  54 , Batch:  24 , loss avg over log interval:  3.615578680038452\n",
            "Epoch:  54 , Batch:  49 , loss avg over log interval:  3.7689111614227295\n",
            "saving model\n",
            "Epoch:  54 , Batch:  74 , loss avg over log interval:  3.771332302093506\n",
            "Epoch:  54 , Batch:  99 , loss avg over log interval:  3.760847692489624\n",
            "saving model\n",
            "Epoch:  54 , Batch:  124 , loss avg over log interval:  3.7664735889434815\n",
            "saving model\n",
            "Epoch:  54 , avg total loss:  3.76717589816002\n",
            "iter   0\n",
            "accuracy so far =  0.7578125\n",
            "Avg Validation Loss:  0.0298593880509033\n",
            "Accuracy:  0.25926602154464123\n",
            "Epoch 54/99 Completed\n",
            "Epoch:  55 , Batch:  0 , loss avg over log interval:  3.738381862640381\n",
            "Epoch:  55 , Batch:  24 , loss avg over log interval:  3.619873456954956\n",
            "Epoch:  55 , Batch:  49 , loss avg over log interval:  3.7790610504150393\n",
            "saving model\n",
            "Epoch:  55 , Batch:  74 , loss avg over log interval:  3.772564468383789\n",
            "Epoch:  55 , Batch:  99 , loss avg over log interval:  3.7749521923065186\n",
            "saving model\n",
            "Epoch:  55 , Batch:  124 , loss avg over log interval:  3.7650712299346925\n",
            "saving model\n",
            "Epoch:  55 , avg total loss:  3.7718654936307097\n",
            "iter   0\n",
            "accuracy so far =  0.6328125\n",
            "Avg Validation Loss:  0.02987341347980482\n",
            "Accuracy:  0.25415373379587364\n",
            "Epoch 55/99 Completed\n",
            "Epoch:  56 , Batch:  0 , loss avg over log interval:  3.7689220905303955\n",
            "Epoch:  56 , Batch:  24 , loss avg over log interval:  3.6172040462493897\n",
            "Epoch:  56 , Batch:  49 , loss avg over log interval:  3.774265909194946\n",
            "saving model\n",
            "Epoch:  56 , Batch:  74 , loss avg over log interval:  3.7664829444885255\n",
            "Epoch:  56 , Batch:  99 , loss avg over log interval:  3.7621727657318114\n",
            "saving model\n",
            "Epoch:  56 , Batch:  124 , loss avg over log interval:  3.767259159088135\n",
            "saving model\n",
            "Epoch:  56 , avg total loss:  3.7683065672443337\n",
            "iter   0\n",
            "accuracy so far =  0.6640625\n",
            "Avg Validation Loss:  0.029822935822107113\n",
            "Accuracy:  0.2616395837137119\n",
            "Epoch 56/99 Completed\n",
            "Epoch:  57 , Batch:  0 , loss avg over log interval:  3.7269723415374756\n",
            "Epoch:  57 , Batch:  24 , loss avg over log interval:  3.624518461227417\n",
            "Epoch:  57 , Batch:  49 , loss avg over log interval:  3.762912769317627\n",
            "saving model\n",
            "Epoch:  57 , Batch:  74 , loss avg over log interval:  3.7697185039520265\n",
            "Epoch:  57 , Batch:  99 , loss avg over log interval:  3.7618189334869383\n",
            "saving model\n",
            "Epoch:  57 , Batch:  124 , loss avg over log interval:  3.754381980895996\n",
            "saving model\n",
            "Epoch:  57 , avg total loss:  3.764899840093639\n",
            "iter   0\n",
            "accuracy so far =  0.671875\n",
            "Avg Validation Loss:  0.02980093575533842\n",
            "Accuracy:  0.2641957275880957\n",
            "Epoch 57/99 Completed\n",
            "Epoch:  58 , Batch:  0 , loss avg over log interval:  3.7422800064086914\n",
            "Epoch:  58 , Batch:  24 , loss avg over log interval:  3.614562301635742\n",
            "Epoch:  58 , Batch:  49 , loss avg over log interval:  3.764920644760132\n",
            "saving model\n",
            "Epoch:  58 , Batch:  74 , loss avg over log interval:  3.7632911300659178\n",
            "Epoch:  58 , Batch:  99 , loss avg over log interval:  3.753230218887329\n",
            "saving model\n",
            "Epoch:  58 , Batch:  124 , loss avg over log interval:  3.762912540435791\n",
            "saving model\n",
            "Epoch:  58 , avg total loss:  3.7631295135576432\n",
            "iter   0\n",
            "accuracy so far =  0.7265625\n",
            "Avg Validation Loss:  0.029789607499188613\n",
            "Accuracy:  0.2638305641774694\n",
            "Epoch 58/99 Completed\n",
            "Epoch:  59 , Batch:  0 , loss avg over log interval:  3.767383098602295\n",
            "Epoch:  59 , Batch:  24 , loss avg over log interval:  3.601477918624878\n",
            "Epoch:  59 , Batch:  49 , loss avg over log interval:  3.7661119556427\n",
            "saving model\n",
            "Epoch:  59 , Batch:  74 , loss avg over log interval:  3.7687557315826417\n",
            "Epoch:  59 , Batch:  99 , loss avg over log interval:  3.7636678218841553\n",
            "saving model\n",
            "saving model\n",
            "Epoch:  59 , avg total loss:  3.7589605099534333\n",
            "iter   0\n",
            "accuracy so far =  0.6875\n",
            "Avg Validation Loss:  0.029748143648304644\n",
            "Accuracy:  0.26967317874748953\n",
            "Epoch 59/99 Completed\n",
            "Epoch:  60 , Batch:  0 , loss avg over log interval:  3.7023699283599854\n",
            "Epoch:  60 , Batch:  24 , loss avg over log interval:  3.6126040840148925\n",
            "Epoch:  60 , Batch:  49 , loss avg over log interval:  3.7650067710876467\n",
            "saving model\n",
            "Epoch:  60 , Batch:  74 , loss avg over log interval:  3.760311098098755\n",
            "Epoch:  60 , Batch:  99 , loss avg over log interval:  3.744340867996216\n",
            "saving model\n",
            "Epoch:  60 , Batch:  124 , loss avg over log interval:  3.7528700733184817\n",
            "saving model\n",
            "Epoch:  60 , avg total loss:  3.758062050767141\n",
            "iter   0\n",
            "accuracy so far =  0.6875\n",
            "Avg Validation Loss:  0.029737918203234435\n",
            "Accuracy:  0.2736899762643783\n",
            "Epoch 60/99 Completed\n",
            "Epoch:  61 , Batch:  0 , loss avg over log interval:  3.7512295246124268\n",
            "Epoch:  61 , Batch:  24 , loss avg over log interval:  3.608712148666382\n",
            "Epoch:  61 , Batch:  49 , loss avg over log interval:  3.7547364234924316\n",
            "saving model\n",
            "Epoch:  61 , Batch:  74 , loss avg over log interval:  3.755462589263916\n",
            "Epoch:  61 , Batch:  99 , loss avg over log interval:  3.758151788711548\n",
            "saving model\n",
            "Epoch:  61 , Batch:  124 , loss avg over log interval:  3.750302028656006\n",
            "saving model\n",
            "Epoch:  61 , avg total loss:  3.7564070665673035\n",
            "iter   0\n",
            "accuracy so far =  0.6484375\n",
            "Avg Validation Loss:  0.02970088557733853\n",
            "Accuracy:  0.28975716633193355\n",
            "Epoch 61/99 Completed\n",
            "Epoch:  62 , Batch:  0 , loss avg over log interval:  3.7282638549804688\n",
            "Epoch:  62 , Batch:  24 , loss avg over log interval:  3.6059388446807863\n",
            "Epoch:  62 , Batch:  49 , loss avg over log interval:  3.7545245361328123\n",
            "saving model\n",
            "Epoch:  62 , Batch:  74 , loss avg over log interval:  3.75889347076416\n",
            "Epoch:  62 , Batch:  99 , loss avg over log interval:  3.743422899246216\n",
            "saving model\n",
            "Epoch:  62 , Batch:  124 , loss avg over log interval:  3.752134838104248\n",
            "saving model\n",
            "Epoch:  62 , avg total loss:  3.7529565716442996\n",
            "iter   0\n",
            "accuracy so far =  0.671875\n",
            "Avg Validation Loss:  0.029683407366830807\n",
            "Accuracy:  0.2966952711338324\n",
            "Epoch 62/99 Completed\n",
            "Epoch:  63 , Batch:  0 , loss avg over log interval:  3.729346752166748\n",
            "Epoch:  63 , Batch:  24 , loss avg over log interval:  3.6026735401153562\n",
            "Epoch:  63 , Batch:  49 , loss avg over log interval:  3.7474918460845945\n",
            "saving model\n",
            "Epoch:  63 , Batch:  74 , loss avg over log interval:  3.7506802082061768\n",
            "Epoch:  63 , Batch:  99 , loss avg over log interval:  3.7426624965667723\n",
            "saving model\n",
            "Epoch:  63 , Batch:  124 , loss avg over log interval:  3.7445431900024415\n",
            "saving model\n",
            "Epoch:  63 , avg total loss:  3.747315658281927\n",
            "iter   0\n",
            "accuracy so far =  0.640625\n",
            "Avg Validation Loss:  0.0296572072675286\n",
            "Accuracy:  0.3007120686507212\n",
            "Epoch 63/99 Completed\n",
            "Epoch:  64 , Batch:  0 , loss avg over log interval:  3.7094802856445312\n",
            "Epoch:  64 , Batch:  24 , loss avg over log interval:  3.6070074081420898\n",
            "Epoch:  64 , Batch:  49 , loss avg over log interval:  3.748293943405151\n",
            "saving model\n",
            "Epoch:  64 , Batch:  74 , loss avg over log interval:  3.749125452041626\n",
            "Epoch:  64 , Batch:  99 , loss avg over log interval:  3.7406665229797365\n",
            "saving model\n",
            "Epoch:  64 , Batch:  124 , loss avg over log interval:  3.743196029663086\n",
            "saving model\n",
            "Epoch:  64 , avg total loss:  3.7476398667244064\n",
            "iter   0\n",
            "accuracy so far =  0.6171875\n",
            "Avg Validation Loss:  0.029622467456126008\n",
            "Accuracy:  0.3034507942304181\n",
            "Epoch 64/99 Completed\n",
            "Epoch:  65 , Batch:  0 , loss avg over log interval:  3.7189950942993164\n",
            "Epoch:  65 , Batch:  24 , loss avg over log interval:  3.6049223518371583\n",
            "Epoch:  65 , Batch:  49 , loss avg over log interval:  3.752347993850708\n",
            "saving model\n",
            "Epoch:  65 , Batch:  74 , loss avg over log interval:  3.7544079971313478\n",
            "Epoch:  65 , Batch:  99 , loss avg over log interval:  3.7334836769104003\n",
            "saving model\n",
            "Epoch:  65 , Batch:  124 , loss avg over log interval:  3.7390161037445067\n",
            "saving model\n",
            "Epoch:  65 , avg total loss:  3.747172283799681\n",
            "iter   0\n",
            "accuracy so far =  0.6640625\n",
            "Avg Validation Loss:  0.029602787845953552\n",
            "Accuracy:  0.3041811210516706\n",
            "Epoch 65/99 Completed\n",
            "Epoch:  66 , Batch:  0 , loss avg over log interval:  3.6835668087005615\n",
            "Epoch:  66 , Batch:  24 , loss avg over log interval:  3.599806547164917\n",
            "Epoch:  66 , Batch:  49 , loss avg over log interval:  3.7529882526397706\n",
            "saving model\n",
            "Epoch:  66 , Batch:  74 , loss avg over log interval:  3.7504443073272706\n",
            "Epoch:  66 , Batch:  99 , loss avg over log interval:  3.7288958740234377\n",
            "saving model\n",
            "Epoch:  66 , Batch:  124 , loss avg over log interval:  3.7410635566711425\n",
            "saving model\n",
            "Epoch:  66 , avg total loss:  3.745597385380366\n",
            "iter   0\n",
            "accuracy so far =  0.7109375\n",
            "Avg Validation Loss:  0.029565581227167258\n",
            "Accuracy:  0.3100237356216907\n",
            "Epoch 66/99 Completed\n",
            "Epoch:  67 , Batch:  0 , loss avg over log interval:  3.7145819664001465\n",
            "Epoch:  67 , Batch:  24 , loss avg over log interval:  3.5958646965026855\n",
            "Epoch:  67 , Batch:  49 , loss avg over log interval:  3.7324666023254394\n",
            "saving model\n",
            "Epoch:  67 , Batch:  74 , loss avg over log interval:  3.7463366985321045\n",
            "Epoch:  67 , Batch:  99 , loss avg over log interval:  3.74488787651062\n",
            "saving model\n",
            "Epoch:  67 , Batch:  124 , loss avg over log interval:  3.7373149299621584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "kA13SNSku3_-",
        "outputId": "1fb2c260-1879-4116-8b22-1ce55f25b13f"
      },
      "source": [
        "data_train[189]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c51f027cea17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m189\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDmKw9pMH3NJ"
      },
      "source": [
        "# Resume Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e2ac1ce20b5e41208342e5a917726d4e",
            "558faa8cc4124de49c3a432e37c04007",
            "604efc3f04374c5fb6d42b7c7168a035",
            "0c11d17f29ab4864845384c6862f629f",
            "e3811e599c794585aded5b04075a8109",
            "790b18b1f19a494bb6bc15cfb14f4e39",
            "425029eadae5419b94cda4c64d988d75",
            "4767defab70242f799e31ec3d7d71b41"
          ]
        },
        "id": "0UlgNih0H2DD",
        "outputId": "db37fc16-1ac4-452b-ac3b-8451daa64af6"
      },
      "source": [
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# initialize weights\n",
        "# for m in spatial.modules():\n",
        "#     if isinstance(m, torch.nn.Linear):\n",
        "#         torch.nn.init.normal_(m.weight, mean = 0, std = 0.01)\n",
        "#         torch.nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 100\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "\n",
        "# LOAD NETWORK\n",
        "network_path = '/content/drive/Shared drives/CIS680 Final Project/models/spatial_new/spatial_epoch8'\n",
        "checkpoint = torch.load(network_path)\n",
        "spatial.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "last_epoch = checkpoint['epoch']\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "accuracy_list = checkpoint['accuracy_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(last_epoch + 1, num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Adjust Learning Rate\n",
        "    # if epoch == 8 or epoch == 13:\n",
        "    #     pass\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'spatial_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': spatial.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2ac1ce20b5e41208342e5a917726d4e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  9 , Batch:  0 , loss avg over log interval:  3.579054117202759\n",
            "Epoch:  9 , Batch:  99 , loss avg over log interval:  3.5460293793678286\n",
            "Epoch:  9 , Batch:  199 , loss avg over log interval:  3.5823871088027954\n",
            "saving model\n",
            "Epoch:  9 , Batch:  299 , loss avg over log interval:  3.5742266011238097\n",
            "Epoch:  9 , Batch:  399 , loss avg over log interval:  3.578859972953796\n",
            "Epoch:  9 , Batch:  499 , loss avg over log interval:  3.5777490186691283\n",
            "saving model\n",
            "Epoch:  9 , Batch:  599 , loss avg over log interval:  3.579861807823181\n",
            "Epoch:  9 , Batch:  699 , loss avg over log interval:  3.5729906296730043\n",
            "saving model\n",
            "Epoch:  9 , Batch:  799 , loss avg over log interval:  3.57385466337204\n",
            "Epoch:  9 , Batch:  899 , loss avg over log interval:  3.5813414573669435\n",
            "Epoch:  9 , Batch:  999 , loss avg over log interval:  3.576751308441162\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1099 , loss avg over log interval:  3.5745735216140746\n",
            "Epoch:  9 , Batch:  1199 , loss avg over log interval:  3.5685772466659547\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1299 , loss avg over log interval:  3.577754440307617\n",
            "Epoch:  9 , Batch:  1399 , loss avg over log interval:  3.5721950912475586\n",
            "Epoch:  9 , Batch:  1499 , loss avg over log interval:  3.5717737030982972\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1599 , loss avg over log interval:  3.578251359462738\n",
            "Epoch:  9 , Batch:  1699 , loss avg over log interval:  3.5745250725746156\n",
            "saving model\n",
            "Epoch:  9 , Batch:  1799 , loss avg over log interval:  3.5757372522354127\n",
            "Epoch:  9 , Batch:  1899 , loss avg over log interval:  3.567928261756897\n",
            "Epoch:  9 , Batch:  1999 , loss avg over log interval:  3.584934277534485\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2099 , loss avg over log interval:  3.577485022544861\n",
            "Epoch:  9 , Batch:  2199 , loss avg over log interval:  3.5743262720108033\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2299 , loss avg over log interval:  3.5728429841995237\n",
            "Epoch:  9 , Batch:  2399 , loss avg over log interval:  3.576960034370422\n",
            "Epoch:  9 , Batch:  2499 , loss avg over log interval:  3.5769550704956057\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2599 , loss avg over log interval:  3.571277866363525\n",
            "Epoch:  9 , Batch:  2699 , loss avg over log interval:  3.5720484018325807\n",
            "saving model\n",
            "Epoch:  9 , Batch:  2799 , loss avg over log interval:  3.5723149943351746\n",
            "Epoch:  9 , Batch:  2899 , loss avg over log interval:  3.5673414778709414\n",
            "Epoch:  9 , Batch:  2999 , loss avg over log interval:  3.5718661737442017\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3099 , loss avg over log interval:  3.5671669363975527\n",
            "Epoch:  9 , Batch:  3199 , loss avg over log interval:  3.5618692779541017\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3299 , loss avg over log interval:  3.5713111758232117\n",
            "Epoch:  9 , Batch:  3399 , loss avg over log interval:  3.575955722332001\n",
            "Epoch:  9 , Batch:  3499 , loss avg over log interval:  3.5696138167381286\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3599 , loss avg over log interval:  3.569198315143585\n",
            "Epoch:  9 , Batch:  3699 , loss avg over log interval:  3.5705218291282654\n",
            "saving model\n",
            "Epoch:  9 , Batch:  3799 , loss avg over log interval:  3.5734462451934816\n",
            "Epoch:  9 , avg total loss:  3.5741825942032306\n",
            "iter   0\n",
            "accuracy so far =  0.9765625\n",
            "iter   100\n",
            "accuracy so far =  0.5340346534653465\n",
            "iter   200\n",
            "accuracy so far =  0.5257307213930348\n",
            "iter   300\n",
            "accuracy so far =  0.5087728405315615\n",
            "iter   400\n",
            "accuracy so far =  0.45086502493765584\n",
            "iter   500\n",
            "accuracy so far =  0.39622317864271456\n",
            "iter   600\n",
            "accuracy so far =  0.43774698419301167\n",
            "iter   700\n",
            "accuracy so far =  0.48912268188302427\n",
            "iter   800\n",
            "accuracy so far =  0.5168734394506866\n",
            "iter   900\n",
            "accuracy so far =  0.5080119311875694\n",
            "iter   1000\n",
            "accuracy so far =  0.503894542957043\n",
            "iter   1100\n",
            "accuracy so far =  0.5036401566757494\n",
            "Avg Validation Loss:  0.028279996895338323\n",
            "Accuracy:  0.49671250909342846\n",
            "Epoch 9/49 Completed\n",
            "Epoch:  10 , Batch:  0 , loss avg over log interval:  3.6594810485839844\n",
            "Epoch:  10 , Batch:  99 , loss avg over log interval:  3.534887034893036\n",
            "Epoch:  10 , Batch:  199 , loss avg over log interval:  3.560631122589111\n",
            "saving model\n",
            "Epoch:  10 , Batch:  299 , loss avg over log interval:  3.5786735010147095\n",
            "Epoch:  10 , Batch:  399 , loss avg over log interval:  3.570725555419922\n",
            "Epoch:  10 , Batch:  499 , loss avg over log interval:  3.5668704223632814\n",
            "saving model\n",
            "Epoch:  10 , Batch:  599 , loss avg over log interval:  3.563460876941681\n",
            "Epoch:  10 , Batch:  699 , loss avg over log interval:  3.5732044100761415\n",
            "saving model\n",
            "Epoch:  10 , Batch:  799 , loss avg over log interval:  3.564046459197998\n",
            "Epoch:  10 , Batch:  899 , loss avg over log interval:  3.559336869716644\n",
            "Epoch:  10 , Batch:  999 , loss avg over log interval:  3.561542465686798\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1099 , loss avg over log interval:  3.572560291290283\n",
            "Epoch:  10 , Batch:  1199 , loss avg over log interval:  3.5655527210235594\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1299 , loss avg over log interval:  3.5702772068977358\n",
            "Epoch:  10 , Batch:  1399 , loss avg over log interval:  3.563330955505371\n",
            "Epoch:  10 , Batch:  1499 , loss avg over log interval:  3.570376570224762\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1599 , loss avg over log interval:  3.5713502097129823\n",
            "Epoch:  10 , Batch:  1699 , loss avg over log interval:  3.567695467472076\n",
            "saving model\n",
            "Epoch:  10 , Batch:  1799 , loss avg over log interval:  3.5666957116127014\n",
            "Epoch:  10 , Batch:  1899 , loss avg over log interval:  3.5684423208236695\n",
            "Epoch:  10 , Batch:  1999 , loss avg over log interval:  3.5663747429847716\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2099 , loss avg over log interval:  3.5645128321647643\n",
            "Epoch:  10 , Batch:  2199 , loss avg over log interval:  3.5729643368721007\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2299 , loss avg over log interval:  3.562355363368988\n",
            "Epoch:  10 , Batch:  2399 , loss avg over log interval:  3.567446722984314\n",
            "Epoch:  10 , Batch:  2499 , loss avg over log interval:  3.5595063948631287\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2599 , loss avg over log interval:  3.564383125305176\n",
            "Epoch:  10 , Batch:  2699 , loss avg over log interval:  3.559916534423828\n",
            "saving model\n",
            "Epoch:  10 , Batch:  2799 , loss avg over log interval:  3.5679066967964173\n",
            "Epoch:  10 , Batch:  2899 , loss avg over log interval:  3.5615393853187562\n",
            "Epoch:  10 , Batch:  2999 , loss avg over log interval:  3.56071852684021\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3099 , loss avg over log interval:  3.568175437450409\n",
            "Epoch:  10 , Batch:  3199 , loss avg over log interval:  3.5698301005363464\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3299 , loss avg over log interval:  3.556127848625183\n",
            "Epoch:  10 , Batch:  3399 , loss avg over log interval:  3.5617884612083435\n",
            "Epoch:  10 , Batch:  3499 , loss avg over log interval:  3.559564802646637\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3599 , loss avg over log interval:  3.5699443101882933\n",
            "Epoch:  10 , Batch:  3699 , loss avg over log interval:  3.558623332977295\n",
            "saving model\n",
            "Epoch:  10 , Batch:  3799 , loss avg over log interval:  3.5667728781700134\n",
            "Epoch:  10 , avg total loss:  3.565968542772589\n",
            "iter   0\n",
            "accuracy so far =  0.890625\n",
            "iter   100\n",
            "accuracy so far =  0.5010829207920792\n",
            "iter   200\n",
            "accuracy so far =  0.5099113805970149\n",
            "iter   300\n",
            "accuracy so far =  0.506047549833887\n",
            "iter   400\n",
            "accuracy so far =  0.4458969763092269\n",
            "iter   500\n",
            "accuracy so far =  0.3964726796407186\n",
            "iter   600\n",
            "accuracy so far =  0.43626507903494177\n",
            "iter   700\n",
            "accuracy so far =  0.49089470399429386\n",
            "iter   800\n",
            "accuracy so far =  0.5203359082397003\n",
            "iter   900\n",
            "accuracy so far =  0.5162666481687015\n",
            "iter   1000\n",
            "accuracy so far =  0.512268981018981\n",
            "iter   1100\n",
            "accuracy so far =  0.5127370004541326\n",
            "Avg Validation Loss:  0.02823190674715891\n",
            "Accuracy:  0.5054075588041709\n",
            "Epoch 10/49 Completed\n",
            "Epoch:  11 , Batch:  0 , loss avg over log interval:  3.545201539993286\n",
            "Epoch:  11 , Batch:  99 , loss avg over log interval:  3.5204057192802427\n",
            "Epoch:  11 , Batch:  199 , loss avg over log interval:  3.5558080220222474\n",
            "saving model\n",
            "Epoch:  11 , Batch:  299 , loss avg over log interval:  3.5599300408363344\n",
            "Epoch:  11 , Batch:  399 , loss avg over log interval:  3.562694766521454\n",
            "Epoch:  11 , Batch:  499 , loss avg over log interval:  3.55555721282959\n",
            "saving model\n",
            "Epoch:  11 , Batch:  599 , loss avg over log interval:  3.5604484820365907\n",
            "Epoch:  11 , Batch:  699 , loss avg over log interval:  3.5552010226249693\n",
            "saving model\n",
            "Epoch:  11 , Batch:  799 , loss avg over log interval:  3.560649333000183\n",
            "Epoch:  11 , Batch:  899 , loss avg over log interval:  3.56130811214447\n",
            "Epoch:  11 , Batch:  999 , loss avg over log interval:  3.5550798988342285\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1099 , loss avg over log interval:  3.55528270483017\n",
            "Epoch:  11 , Batch:  1199 , loss avg over log interval:  3.567438428401947\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1299 , loss avg over log interval:  3.5572629570961\n",
            "Epoch:  11 , Batch:  1399 , loss avg over log interval:  3.5556547331809996\n",
            "Epoch:  11 , Batch:  1499 , loss avg over log interval:  3.5591497564315797\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1599 , loss avg over log interval:  3.563854157924652\n",
            "Epoch:  11 , Batch:  1699 , loss avg over log interval:  3.5550047087669374\n",
            "saving model\n",
            "Epoch:  11 , Batch:  1799 , loss avg over log interval:  3.5547358536720277\n",
            "Epoch:  11 , Batch:  1899 , loss avg over log interval:  3.5626550936698913\n",
            "Epoch:  11 , Batch:  1999 , loss avg over log interval:  3.555945646762848\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2099 , loss avg over log interval:  3.5584344935417174\n",
            "Epoch:  11 , Batch:  2199 , loss avg over log interval:  3.556195936203003\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2299 , loss avg over log interval:  3.5598151588439944\n",
            "Epoch:  11 , Batch:  2399 , loss avg over log interval:  3.5551564145088195\n",
            "Epoch:  11 , Batch:  2499 , loss avg over log interval:  3.5538482809066774\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2599 , loss avg over log interval:  3.5663298058509825\n",
            "Epoch:  11 , Batch:  2699 , loss avg over log interval:  3.5543218898773192\n",
            "saving model\n",
            "Epoch:  11 , Batch:  2799 , loss avg over log interval:  3.5483792662620544\n",
            "Epoch:  11 , Batch:  2899 , loss avg over log interval:  3.5596454095840455\n",
            "Epoch:  11 , Batch:  2999 , loss avg over log interval:  3.5616452145576476\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3099 , loss avg over log interval:  3.553210859298706\n",
            "Epoch:  11 , Batch:  3199 , loss avg over log interval:  3.5537309050559998\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3299 , loss avg over log interval:  3.556489462852478\n",
            "Epoch:  11 , Batch:  3399 , loss avg over log interval:  3.5549196076393126\n",
            "Epoch:  11 , Batch:  3499 , loss avg over log interval:  3.5470906352996825\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3599 , loss avg over log interval:  3.5557191348075867\n",
            "Epoch:  11 , Batch:  3699 , loss avg over log interval:  3.5440936303138733\n",
            "saving model\n",
            "Epoch:  11 , Batch:  3799 , loss avg over log interval:  3.546159794330597\n",
            "Epoch:  11 , avg total loss:  3.556547733444079\n",
            "iter   0\n",
            "accuracy so far =  1.0\n",
            "iter   100\n",
            "accuracy so far =  0.5326423267326733\n",
            "iter   200\n",
            "accuracy so far =  0.5050528606965174\n",
            "iter   300\n",
            "accuracy so far =  0.5082018272425249\n",
            "iter   400\n",
            "accuracy so far =  0.4494427992518703\n",
            "iter   500\n",
            "accuracy so far =  0.39458582834331335\n",
            "iter   600\n",
            "accuracy so far =  0.42543677204658903\n",
            "iter   700\n",
            "accuracy so far =  0.4794155670470756\n",
            "iter   800\n",
            "accuracy so far =  0.505500936329588\n",
            "iter   900\n",
            "accuracy so far =  0.5127635960044395\n",
            "iter   1000\n",
            "accuracy so far =  0.5056037712287712\n",
            "iter   1100\n",
            "accuracy so far =  0.5030512034514079\n",
            "Avg Validation Loss:  0.028270143950018953\n",
            "Accuracy:  0.496428447708456\n",
            "Epoch 11/49 Completed\n",
            "Epoch:  12 , Batch:  0 , loss avg over log interval:  3.593905448913574\n",
            "Epoch:  12 , Batch:  99 , loss avg over log interval:  3.521117215156555\n",
            "Epoch:  12 , Batch:  199 , loss avg over log interval:  3.552168846130371\n",
            "saving model\n",
            "Epoch:  12 , Batch:  299 , loss avg over log interval:  3.5547372937202453\n",
            "Epoch:  12 , Batch:  399 , loss avg over log interval:  3.550812337398529\n",
            "Epoch:  12 , Batch:  499 , loss avg over log interval:  3.5568406987190246\n",
            "saving model\n",
            "Epoch:  12 , Batch:  599 , loss avg over log interval:  3.5536263036727904\n",
            "Epoch:  12 , Batch:  699 , loss avg over log interval:  3.548257262706757\n",
            "saving model\n",
            "Epoch:  12 , Batch:  799 , loss avg over log interval:  3.5533126187324524\n",
            "Epoch:  12 , Batch:  899 , loss avg over log interval:  3.556446475982666\n",
            "Epoch:  12 , Batch:  999 , loss avg over log interval:  3.54851273059845\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1099 , loss avg over log interval:  3.5536370778083803\n",
            "Epoch:  12 , Batch:  1199 , loss avg over log interval:  3.552349154949188\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1299 , loss avg over log interval:  3.557411675453186\n",
            "Epoch:  12 , Batch:  1399 , loss avg over log interval:  3.5463144111633302\n",
            "Epoch:  12 , Batch:  1499 , loss avg over log interval:  3.5458537459373476\n",
            "saving model\n",
            "Epoch:  12 , Batch:  1599 , loss avg over log interval:  3.553555226325989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy2dqXCRNr7g"
      },
      "source": [
        "# Calculate Accuracy of a Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-Nbs6zlNy_0",
        "outputId": "13228753-b908-4e29-b156-c53cdec81fb3"
      },
      "source": [
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# model\n",
        "learning_rate = 0.001\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "optimizer = optim.SGD(spatial.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# LOAD NETWORK\n",
        "network_path = '/content/drive/Shared drives/CIS680 Final Project/models/spatial/spatial_epoch0'\n",
        "checkpoint = torch.load(network_path)\n",
        "spatial.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "last_epoch = checkpoint['epoch']\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "iter   10\n",
            "accuracy so far =  1.0\n",
            "Avg Validation Loss:  0.0002464993757317368\n",
            "Accuracy:  0.009755083659542037\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}