{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FuseNet_Sampled.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgqAhYHvNg2"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA580dbFbyEn",
        "outputId": "15d00522-04b0-423a-c6d5-bf68c8aa1479"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOC44nKYDOn8"
      },
      "source": [
        "# Run this command once and restart the runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZffaB6C7Z7",
        "outputId": "430a360c-e65a-452f-effb-041483681c19"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/62/9a992be76f8e13ce0e3a24a838191b546805545116f9fc869bd11bd21b5f/av-8.0.2-cp36-cp36m-manylinux2010_x86_64.whl (36.9MB)\n",
            "\u001b[K     |████████████████████████████████| 36.9MB 1.3MB/s \n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-8.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwpGXLdtuq8i"
      },
      "source": [
        "# Mount drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6nsoL9Kuqil",
        "outputId": "3d0e73ba-4dc0-4584-cbbe-026183653cac"
      },
      "source": [
        "import os\n",
        "import io\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount google drive\n",
        "DRIVE_MOUNT='/content/drive'\n",
        "\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "\n",
        "# create folder to write data to\n",
        "DATA_FOLDER = os.path.join(DRIVE_MOUNT, 'Shared drives', 'CIS680 Final Project', 'data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwe7Gmz2EHZp"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4hrmV77EGvg",
        "outputId": "7db396f8-4720-4d28-a21c-d6e37205807e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms\n",
        "from torch import nn, Tensor\n",
        "# from dataset import *\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "train_size = 138\n",
        "test_size = 41\n",
        "\n",
        "train_path = DATA_FOLDER + \"/dataset_3/train/train_b\"\n",
        "test_path = DATA_FOLDER + \"/dataset_3/test/test_b\"\n",
        "\n",
        "train_loader = []\n",
        "test_loader = []\n",
        "\n",
        "for batch in range(train_size):\n",
        "    batch_path = train_path + str(batch) + \".pt\"\n",
        "    train_loader.append(torch.load(batch_path))\n",
        "    if batch % 10 == 0:\n",
        "        print(\"train: \" + str(batch) + \"/\" + str(train_size))\n",
        "\n",
        "for batch in range(test_size):\n",
        "    batch_path = test_path + str(batch) + \".pt\"\n",
        "    test_loader.append(torch.load(batch_path))\n",
        "    if batch % 10 == 0:\n",
        "        print(\"test: \" + str(batch) + \"/\" + str(test_size))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 0/138\n",
            "train: 10/138\n",
            "train: 20/138\n",
            "train: 30/138\n",
            "train: 40/138\n",
            "train: 50/138\n",
            "train: 60/138\n",
            "train: 70/138\n",
            "train: 80/138\n",
            "train: 90/138\n",
            "train: 100/138\n",
            "train: 110/138\n",
            "train: 120/138\n",
            "train: 130/138\n",
            "test: 0/41\n",
            "test: 10/41\n",
            "test: 20/41\n",
            "test: 30/41\n",
            "test: 40/41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo6FpL-ddpSI"
      },
      "source": [
        "# Spatial Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8J0AEPhdqg8"
      },
      "source": [
        "class SpatialStream(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 device='cuda',\n",
        "                 num_classes=51,\n",
        "                 dropout_probability=0.5,\n",
        "                 train_resnet=True):\n",
        "\n",
        "        # Initialize the stream layers\n",
        "        super(SpatialStream, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Spatial Backbone\n",
        "        self.spatial = models.resnet50(pretrained=True)\n",
        "        for param in self.spatial.parameters():\n",
        "            param.requires_grad = train_resnet  # False: Freezes the weights of the pre-trained model\n",
        "\n",
        "        # Add to Spatial Backbone\n",
        "        self.spatial.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Linear(1024, self.num_classes),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Softmax())\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.spatial(X)\n",
        "\n",
        "    def compute_loss(self, output, labels):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # labels = torch.tensor(labels)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        return loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR8qQX0YT83S"
      },
      "source": [
        "# Temporal Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlaLhE8VT8U0"
      },
      "source": [
        "class TemporalStream(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 device='cuda',\n",
        "                 num_classes=51,\n",
        "                 dropout_probability=0.5):\n",
        "\n",
        "        # Initialize the stream layers\n",
        "        super(TemporalStream, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Backbone\n",
        "        self.temporal = models.resnet50(pretrained=True)\n",
        "        for param in self.temporal.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        #self.temporal.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3)\n",
        "\n",
        "        self.temporal.fc = nn.Sequential(nn.Linear(2048, 1024),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Linear(1024, self.num_classes),\n",
        "                                nn.ReLU(),\n",
        "                                nn.Dropout(p=dropout_probability),\n",
        "                                nn.Softmax())\n",
        "        \n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.temporal(X)\n",
        "        return X\n",
        "\n",
        "    def compute_loss(self, output, target):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(output, target)\n",
        "        return loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BkCNZhhT_70"
      },
      "source": [
        "# Fuse Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeUFQULLT_Kl"
      },
      "source": [
        "class FuseNET(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, \n",
        "                 device='cuda',\n",
        "                 num_classes=51):\n",
        "\n",
        "        # Initialize the stream layers\n",
        "        super(FuseNET, self).__init__()\n",
        "        self.device = device\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.fc1 = nn.Linear(102, 204)\n",
        "        self.output = nn.Linear(204, self.num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.fc1(X)\n",
        "        X = self.output(X)\n",
        "        return X\n",
        "\n",
        "    def compute_loss(self, output, labels):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # labels = torch.tensor(labels)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        return loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pEvnrSVeftj"
      },
      "source": [
        "# Video Frame Stacking (SG3I)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LIHVXrkzK1N"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2 as cv\n",
        "\n",
        "def getSG3I(videos):\n",
        "    bz = videos.size(0)\n",
        "\n",
        "    frame_list_batch = []\n",
        "\n",
        "    for b in range(bz):\n",
        "        images = videos[b]\n",
        "\n",
        "        w = images[0].size(0)\n",
        "        h = images[0].size(1)\n",
        "        num_frames = images.size(0)\n",
        "        frame_list = []\n",
        "\n",
        "        for i in range(0, num_frames):\n",
        "            frame_list.append(cv.cvtColor(images[i].numpy(), cv.COLOR_BGR2GRAY))\n",
        "\n",
        "        frame_list_batch.append(np.stack(frame_list, axis=-1))\n",
        "\n",
        "    SG3I = np.stack(frame_list_batch, axis=0)\n",
        "    #cv2_imshow(SG3I[0])\n",
        "\n",
        "    return torch.Tensor(SG3I)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU4tMD-_E4Aw"
      },
      "source": [
        "# Train and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkzqmwzefQq"
      },
      "source": [
        "  def train(epoch):\n",
        "    spatial.eval()\n",
        "    temporal.eval()\n",
        "    fused.train()\n",
        "\n",
        "    counter = 0\n",
        "    train_loss = 0\n",
        "    log_interval = 100\n",
        "    save_interval = 250\n",
        "\n",
        "    epoch_loss = []\n",
        "    log_int_loss = 0\n",
        "    for iter, data in enumerate(train_loader, 0):\n",
        "\n",
        "        videos = data[\"videos\"]\n",
        "        labels = torch.tensor(data[\"labels\"])\n",
        "        indexes = data[\"indexes\"]\n",
        "        \n",
        "        SG3I = getSG3I(videos)\n",
        "        SG3I = SG3I.permute(0,3,1,2)\n",
        "        SG3I = SG3I.to(device)\n",
        "\n",
        "        videos = videos.type(torch.FloatTensor)\n",
        "        videos = videos.to(device)\n",
        "        # labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # spatial\n",
        "        spatial_input = videos[:,0,:,:].permute(0,3,2,1)\n",
        "        spatial_output = spatial(spatial_input)\n",
        "\n",
        "        # temporal        \n",
        "        temporal_output = temporal(SG3I)\n",
        "        \n",
        "        # fused\n",
        "        fused_input = torch.hstack((spatial_output, temporal_output))\n",
        "        fused_output = fused(fused_input)\n",
        "\n",
        "        fused_output = fused_output.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # calculate losses\n",
        "        loss = fused.compute_loss(fused_output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Logging Interval\n",
        "        log_int_loss += loss.item()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if counter == 0:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss)\n",
        "            train_loss_list.append(train_loss / (iter + 1) * batch_size)\n",
        "            train_counter.append((iter + 1) * batch_size + epoch * len(train_loader.dataset))\n",
        "            log_int_loss = 0\n",
        "        elif counter % log_interval == log_interval - 1:\n",
        "            print('Epoch: ', epoch, ', Batch: ', iter, ', loss avg over log interval: ', log_int_loss / log_interval)\n",
        "            train_loss_list.append(train_loss / (iter + 1) * batch_size)\n",
        "            train_counter.append((iter + 1) * batch_size + epoch * len(train_loader.dataset))\n",
        "            log_int_loss = 0\n",
        "\n",
        "        if counter % save_interval == save_interval - 1:\n",
        "            print('saving model')\n",
        "            save_path = os.path.join(EPOCH_SAVE_PREFIX, 'fused_epoch' + str(epoch) + '_iter_' + str(counter))\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_total_loss_list': train_loss_list,\n",
        "                'epoch_total_loss_list': epoch_loss_list,\n",
        "                'test_loss_list': test_loss_list,\n",
        "                'train_counter': train_counter,\n",
        "                'accuracy_list': accuracy_list,\n",
        "                'model_state_dict': fused.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, save_path)\n",
        "\n",
        "        counter += 1\n",
        "\n",
        "\n",
        "    avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "    epoch_loss_list.append(avg_loss)\n",
        "    print('Epoch: ', epoch, ', avg total loss: ', avg_loss)\n",
        "\n",
        "def test():\n",
        "    fused.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Data Loop\n",
        "    with torch.no_grad():\n",
        "        for iter, data in enumerate(test_loader, 0):\n",
        "            videos = data[\"videos\"]\n",
        "            labels = torch.tensor(data[\"labels\"])\n",
        "            indexes = data[\"indexes\"]\n",
        "            \n",
        "            SG3I = getSG3I(videos)\n",
        "            SG3I = SG3I.permute(0,3,1,2)\n",
        "            SG3I = SG3I.to(device)\n",
        "\n",
        "            videos = videos.type(torch.FloatTensor)\n",
        "            videos = videos.to(device)\n",
        "            # labels = labels.to(device)\n",
        "\n",
        "            # spatial\n",
        "            spatial_input = videos[:,0,:,:].permute(0,3,2,1)\n",
        "            spatial_output = spatial(spatial_input)\n",
        "\n",
        "            # temporal        \n",
        "            temporal_output = temporal(SG3I)\n",
        "            \n",
        "            # fused\n",
        "            fused_input = torch.hstack((spatial_output, temporal_output))\n",
        "            fused_output = fused(fused_input)\n",
        "\n",
        "            fused_output = fused_output.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # calculate losses\n",
        "            loss = fused.compute_loss(fused_output, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # calculate number of correct predictions in batch\n",
        "            correct += sum(torch.argmax(fused_output,1) == labels).item()\n",
        "            if iter % 100 == 0:\n",
        "                print (\"iter  \", iter)\n",
        "                print(\"accuracy so far = \", correct / ((iter + 1) * len(labels)))\n",
        "\n",
        "    # Log\n",
        "    test_loss_list.append(test_loss / len(test_loader.dataset))\n",
        "    accuracy = correct / len(test_loader.dataset)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print('Avg Validation Loss: ', test_loss / len(test_loader.dataset))\n",
        "    print('Accuracy: ', accuracy)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxNfXCLLYcbW"
      },
      "source": [
        "# Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiW7i49DYbwc"
      },
      "source": [
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/fused_sampled/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# load trained spatial\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "spatial_network_path = '/content/drive/Shared drives/CIS680 Final Project/models/spatial/spatial_epoch10'\n",
        "checkpoint_spatial = torch.load(spatial_network_path)\n",
        "spatial.load_state_dict(checkpoint_spatial['model_state_dict'])\n",
        "\n",
        "# load trained temporal\n",
        "temporal = TemporalStream()\n",
        "temporal.to(device)\n",
        "temporal_network_path = '/content/drive/Shared drives/CIS680 Final Project/models/temporal_SG3I/temporal_epoch8'\n",
        "checkpoint_temporal = torch.load(temporal_network_path)\n",
        "temporal.load_state_dict(checkpoint_temporal['model_state_dict'])\n",
        "\n",
        "\n",
        "# fused model\n",
        "learning_rate = 0.001\n",
        "fused = FuseNET()\n",
        "fused.to(device)\n",
        "optimizer = optim.SGD(fused.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 50\n",
        "batch_size = 128\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = []\n",
        "epoch_loss_list = []\n",
        "train_counter = []\n",
        "\n",
        "# Logging setup: test\n",
        "test_loss_list = []\n",
        "accuracy_list = []\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'fused_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': fused.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDmKw9pMH3NJ"
      },
      "source": [
        "# Resume Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UlgNih0H2DD"
      },
      "source": [
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/fused_sampled/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# load trained spatial\n",
        "spatial = SpatialStream()\n",
        "spatial.to(device)\n",
        "spatial_network_path = '/content/drive/Shared drives/CIS680 Final Project/models/spatial/spatial_epoch10'\n",
        "checkpoint_spatial = torch.load(spatial_network_path)\n",
        "spatial.load_state_dict(checkpoint_spatial['model_state_dict'])\n",
        "\n",
        "# load trained temporal\n",
        "temporal = TemporalStream()\n",
        "temporal.to(device)\n",
        "temporal_network_path = '/content/drive/Shared drives/CIS680 Final Project/models/temporal_SG3I/temporal_epoch8'\n",
        "checkpoint_temporal = torch.load(temporal_network_path)\n",
        "temporal.load_state_dict(checkpoint_temporal['model_state_dict'])\n",
        "\n",
        "\n",
        "# fused model\n",
        "learning_rate = 0.001\n",
        "fused = FuseNET()\n",
        "fused.to(device)\n",
        "optimizer = optim.SGD(fused.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "# Epochs\n",
        "num_epochs = 250\n",
        "batch_size = 128\n",
        "epoch_list = np.arange(num_epochs)\n",
        "\n",
        "\n",
        "# LOAD NETWORK\n",
        "fused_network_path = '/content/drive/Shared drives/CIS680 Final Project/models/fused_sampled/fused_epoch1'\n",
        "checkpoint_fused = torch.load(fused_network_path)\n",
        "fused.load_state_dict(checkpoint_fused['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint_fused['optimizer_state_dict'])\n",
        "last_epoch = checkpoint_fused['epoch']\n",
        "\n",
        "# Logging setup: train\n",
        "train_loss_list = checkpoint_fused['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint_fused['epoch_total_loss_list']\n",
        "\n",
        "test_loss_list = checkpoint_fused['test_loss_list']\n",
        "accuracy_list = checkpoint_fused['accuracy_list']\n",
        "train_counter = checkpoint_fused['train_counter']\n",
        "\n",
        "\n",
        "# epoch loop\n",
        "for epoch in range(last_epoch + 1, num_epochs):\n",
        "\n",
        "    # Train & Validate\n",
        "    train(epoch)\n",
        "    test()\n",
        "\n",
        "    # Save Model Version\n",
        "    save_path = os.path.join(EPOCH_SAVE_PREFIX, 'fused_epoch' + str(epoch))\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'train_total_loss_list': train_loss_list,\n",
        "        'epoch_total_loss_list': epoch_loss_list,\n",
        "        'test_loss_list': test_loss_list,\n",
        "        'train_counter': train_counter,\n",
        "        'accuracy_list': accuracy_list,\n",
        "        'model_state_dict': fused.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "\n",
        "    print(\"Epoch %d/%d Completed\" % (epoch, num_epochs - 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWSTqvq_FBZb"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q4XGcuDFCLX"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "EPOCH_SAVE_PREFIX = '/content/drive/Shared drives/CIS680 Final Project/models/fused_sampled/'\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "torch.random.manual_seed(1)\n",
        "\n",
        "# Load params\n",
        "last_epoch = 100\n",
        "\n",
        "# load data\n",
        "network_path = EPOCH_SAVE_PREFIX + 'fused_epoch' + str(last_epoch)\n",
        "checkpoint = torch.load(network_path)\n",
        "train_loss_list = checkpoint['train_total_loss_list']\n",
        "epoch_loss_list = checkpoint['epoch_total_loss_list']\n",
        "train_counter = checkpoint['train_counter']\n",
        "test_loss_list = checkpoint['test_loss_list']\n",
        "accuracy_list = checkpoint['accuracy_lsit']\n",
        "epoch_list = np.arange(last_epoch+1)\n",
        "\n",
        "\n",
        "# plots\n",
        "fig = plt.figure()\n",
        "plt.plot(epoch_loss_list, color='blue')\n",
        "plt.legend(['FuseNet Train Loss'], loc='upper right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Total Loss')\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(test_loss_list, color='green')\n",
        "plt.legend(['FuseNet Validation Loss'], loc='upper right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Total Loss')\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(accuracy_list, color='red')\n",
        "plt.legend(['FuseNet Validation Accuracy'], loc='lower right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}